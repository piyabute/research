{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy algorithms\n",
    "# - K-nearest Neighbors\n",
    "# - Local Regression\n",
    "# - Lazy Naive Bayes (Naive Bayes + Kernel Density Estimation (KDE))\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html\n",
    "\n",
    "# Imbalance data handling\n",
    "# - Random under-sampling\n",
    "# - Random over-sampling\n",
    "# - NearMiss\n",
    "\n",
    "# Domains\n",
    "# - Fraud detection\n",
    "# - Spam filtering\n",
    "# - Disease screening\n",
    "# - SaaS subscription churn\n",
    "# - Advertising click-throughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 0\n",
      "Data Source: https://piyabute.com/data/research/banknote_authentication.csv\n",
      "Preprocessing: Attribute = 5 [0 1 2 3 4E ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 4 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 1372\n",
      "Preprocessing: Class     = 2 [0 1]\n",
      "Preprocessing: Train     = {0: 762, 1: 610}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 1.36 seconds / Size = 77 / Original = 1372 / Remain = 1295\n",
      "Reduction: Level 2 is constructed. / Time = 0.44 seconds / Size = 78 / Original = 1295 / Remain = 1217\n",
      "Reduction: Level 3 is constructed. / Time = 0.52 seconds / Size = 72 / Original = 1217 / Remain = 1145\n",
      "Reduction: Level 4 is constructed. / Time = 0.45 seconds / Size = 74 / Original = 1145 / Remain = 1071\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=0; sample=1372 (100.00%) {0: 762, 1: 610}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=1372; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=0; sample=17 (1.24%) {0: 16, 1: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=17; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=0; sample=1372 (100.00%) {0: 762, 1: 610}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=1372; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=0; sample=1372 (100.00%) {0: 762, 1: 610}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=1372; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=0; sample=1372 (100.00%) {0: 762, 1: 610}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=1372; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 5 TL; set=0; sample=1372 (100.00%) {0: 762, 1: 610}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=1372; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=0; sample=644 (46.94%) {0: 643, 1: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=644; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=0; sample=1372 (100.00%) {0: 762, 1: 610}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=1372; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=0; sample=1220 (88.92%) {0: 610, 1: 610}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=1220; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=0; sample=1220 (88.92%) {0: 610, 1: 610}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=1220; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 10 NM$_3$; set=0; sample=674 (49.13%) {0: 64, 1: 610}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=674; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=0; sample=1280 (93.29%) {0: 670, 1: 610}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=1280; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=0; sample=1220 (88.92%) {0: 610, 1: 610}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=1220; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=0; sample=1220 (88.92%) {0: 610, 1: 610}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=1220; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=0; sample=77 (5.61%) {0: 24, 1: 53}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=0; sample=103 (7.51%) {0: 50, 1: 53}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=103; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.98; AUC OVO=0.98\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=0; sample=155 (11.30%) {0: 51, 1: 104}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=0; sample=155 (11.30%) {0: 51, 1: 104}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=155; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.96; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=0; sample=227 (16.55%) {0: 70, 1: 157}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=0; sample=227 (16.55%) {0: 70, 1: 157}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=227; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=0; sample=301 (21.94%) {0: 93, 1: 208}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=0; sample=301 (21.94%) {0: 93, 1: 208}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=301; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 0 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 1\n",
      "Data Source: https://piyabute.com/data/research/car.data.csv\n",
      "Preprocessing: Attribute = 7 [0E 1E 2E 3E 4E 5E 6E ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 6 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 1728\n",
      "Preprocessing: Class     = 4 [0 1 2 3]\n",
      "Preprocessing: Train     = {0: 384, 1: 69, 2: 1210, 3: 65}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 1.07 seconds / Size = 679 / Original = 1728 / Remain = 1049\n",
      "Reduction: Level 2 is constructed. / Time = 0.26 seconds / Size = 35 / Original = 1049 / Remain = 1014\n",
      "Reduction: Level 3 is constructed. / Time = 0.24 seconds / Size = 1 / Original = 1014 / Remain = 1013\n",
      "Reduction: Level 4 is constructed. / Time = 0.24 seconds / Size = 1 / Original = 1013 / Remain = 1012\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=1; sample=1728 (100.00%) {0: 384, 1: 69, 2: 1210, 3: 65}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=1728; Acc=0.93; Pre=0.94; Recall=0.93; F1=0.93; AUC OVR=0.98; AUC OVO=0.97\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=1; sample=177 (10.24%) {0: 80, 1: 17, 2: 79, 3: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=177; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=1; sample=1643 (95.08%) {0: 377, 1: 50, 2: 1152, 3: 64}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=1643; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=1; sample=1643 (95.08%) {0: 377, 1: 50, 2: 1152, 3: 64}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=1643; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=1; sample=1660 (96.06%) {0: 363, 1: 57, 2: 1181, 3: 59}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=1660; Acc=0.95; Pre=0.96; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 5 TL; set=1; sample=1684 (97.45%) {0: 368, 1: 59, 2: 1197, 3: 60}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=1684; Acc=0.94; Pre=0.95; Recall=0.94; F1=0.94; AUC OVR=0.98; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=1; sample=1243 (71.93%) {0: 360, 1: 28, 2: 854, 3: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=1243; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=1; sample=1643 (95.08%) {0: 377, 1: 50, 2: 1152, 3: 64}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=1643; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=1; sample=260 (15.05%) {0: 65, 1: 65, 2: 65, 3: 65}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=260; Acc=0.86; Pre=0.88; Recall=0.86; F1=0.86; AUC OVR=0.95; AUC OVO=0.95\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=1; sample=260 (15.05%) {0: 65, 1: 65, 2: 65, 3: 65}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=260; Acc=0.91; Pre=0.92; Recall=0.91; F1=0.91; AUC OVR=0.97; AUC OVO=0.97\n",
      "\n",
      "Training: (Post) Type 10 NM$_3$; set=1; sample=219 (12.67%) {0: 65, 1: 24, 2: 65, 3: 65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=219; Acc=0.82; Pre=0.85; Recall=0.82; F1=0.82; AUC OVR=0.95; AUC OVO=0.95\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=1; sample=702 (40.62%) {0: 70, 1: 65, 2: 502, 3: 65}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=702; Acc=0.96; Pre=0.97; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=1; sample=260 (15.05%) {0: 65, 1: 65, 2: 65, 3: 65}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=260; Acc=0.63; Pre=0.66; Recall=0.63; F1=0.59; AUC OVR=0.83; AUC OVO=0.83\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=1; sample=260 (15.05%) {0: 65, 1: 65, 2: 65, 3: 65}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=260; Acc=0.72; Pre=0.76; Recall=0.72; F1=0.71; AUC OVR=0.89; AUC OVO=0.89\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=1; sample=679 (39.29%) {0: 366, 1: 69, 2: 179, 3: 65}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=1; sample=679 (39.29%) {0: 366, 1: 69, 2: 179, 3: 65}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=679; Acc=0.79; Pre=0.82; Recall=0.79; F1=0.77; AUC OVR=0.87; AUC OVO=0.91\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=1; sample=714 (41.32%) {0: 384, 1: 69, 2: 196, 3: 65}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=1; sample=714 (41.32%) {0: 384, 1: 69, 2: 196, 3: 65}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=714; Acc=0.79; Pre=0.83; Recall=0.79; F1=0.78; AUC OVR=0.88; AUC OVO=0.92\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=1; sample=715 (41.38%) {0: 384, 1: 69, 2: 197, 3: 65}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=1; sample=715 (41.38%) {0: 384, 1: 69, 2: 197, 3: 65}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=715; Acc=0.80; Pre=0.83; Recall=0.80; F1=0.78; AUC OVR=0.88; AUC OVO=0.92\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=1; sample=716 (41.44%) {0: 384, 1: 69, 2: 198, 3: 65}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=1; sample=716 (41.44%) {0: 384, 1: 69, 2: 198, 3: 65}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=716; Acc=0.79; Pre=0.83; Recall=0.79; F1=0.77; AUC OVR=0.88; AUC OVO=0.92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 1 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 2\n",
      "Data Source: https://piyabute.com/data/research/crowdsourced_mapping.custom.csv\n",
      "Preprocessing: Attribute = 29 [0E 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 26 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 10844\n",
      "Preprocessing: Class     = 6 [0 1 2 3 4 5]\n",
      "Preprocessing: Train     = {0: 1494, 1: 7509, 2: 482, 3: 1009, 4: 100, 5: 250}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 55.73 seconds / Size = 2096 / Original = 10844 / Remain = 8748\n",
      "Reduction: Level 2 is constructed. / Time = 25.22 seconds / Size = 1265 / Original = 8748 / Remain = 7483\n",
      "Reduction: Level 3 is constructed. / Time = 10.70 seconds / Size = 618 / Original = 7483 / Remain = 6865\n",
      "Reduction: Level 4 is constructed. / Time = 4.56 seconds / Size = 213 / Original = 6865 / Remain = 6652\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=2; sample=10844 (100.00%) {0: 1494, 1: 7509, 2: 482, 3: 1009, 4: 100, 5: 250}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=10844; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.98; AUC OVO=0.97\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=2; sample=485 (4.47%) {0: 121, 1: 271, 2: 33, 3: 42, 4: 1, 5: 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=485; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=2; sample=10426 (96.15%) {0: 1393, 1: 7403, 2: 414, 3: 944, 4: 68, 5: 204}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=10426; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=2; sample=10353 (95.47%) {0: 1359, 1: 7397, 2: 397, 3: 940, 4: 58, 5: 202}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=10353; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=2; sample=10241 (94.44%) {0: 1331, 1: 7365, 2: 396, 3: 900, 4: 51, 5: 198}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=10241; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 5 TL; set=2; sample=10732 (98.97%) {0: 1466, 1: 7489, 2: 462, 3: 981, 4: 90, 5: 244}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=10732; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.97\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=2; sample=9239 (85.20%) {0: 1381, 1: 7234, 2: 382, 3: 177, 4: 1, 5: 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=9239; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=2; sample=10398 (95.89%) {0: 1393, 1: 7375, 2: 414, 3: 944, 4: 68, 5: 204}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=10398; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=2; sample=600 (5.53%) {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=600; Acc=0.83; Pre=0.85; Recall=0.83; F1=0.83; AUC OVR=0.95; AUC OVO=0.95\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=2; sample=600 (5.53%) {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=600; Acc=0.79; Pre=0.82; Recall=0.79; F1=0.79; AUC OVR=0.92; AUC OVO=0.92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 10 NM$_3$; set=2; sample=547 (5.04%) {0: 100, 1: 100, 2: 100, 3: 95, 4: 100, 5: 52}\n",
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=547; Acc=0.64; Pre=0.67; Recall=0.64; F1=0.64; AUC OVR=0.87; AUC OVO=0.86\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=2; sample=803 (7.41%) {0: 112, 1: 256, 2: 101, 3: 133, 4: 100, 5: 101}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=803; Acc=0.96; Pre=0.97; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=2; sample=600 (5.53%) {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=600; Acc=0.70; Pre=0.74; Recall=0.70; F1=0.70; AUC OVR=0.88; AUC OVO=0.88\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=2; sample=600 (5.53%) {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=600; Acc=0.73; Pre=0.77; Recall=0.73; F1=0.72; AUC OVR=0.91; AUC OVO=0.91\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=2; sample=2096 (19.33%) {0: 754, 1: 452, 2: 329, 3: 425, 4: 60, 5: 76}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=2; sample=2096 (19.33%) {0: 754, 1: 452, 2: 329, 3: 425, 4: 60, 5: 76}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=2096; Acc=0.72; Pre=0.73; Recall=0.72; F1=0.71; AUC OVR=0.89; AUC OVO=0.87\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=2; sample=3361 (30.99%) {0: 1239, 1: 779, 2: 462, 3: 660, 4: 90, 5: 131}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=2; sample=3361 (30.99%) {0: 1239, 1: 779, 2: 462, 3: 660, 4: 90, 5: 131}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=3361; Acc=0.82; Pre=0.82; Recall=0.82; F1=0.81; AUC OVR=0.94; AUC OVO=0.93\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=2; sample=3979 (36.69%) {0: 1455, 1: 942, 2: 481, 3: 827, 4: 95, 5: 179}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=2; sample=3979 (36.69%) {0: 1455, 1: 942, 2: 481, 3: 827, 4: 95, 5: 179}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=3979; Acc=0.84; Pre=0.85; Recall=0.84; F1=0.84; AUC OVR=0.95; AUC OVO=0.94\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=2; sample=4192 (38.66%) {0: 1490, 1: 977, 2: 482, 3: 931, 4: 99, 5: 213}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=2; sample=4192 (38.66%) {0: 1490, 1: 977, 2: 482, 3: 931, 4: 99, 5: 213}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=4192; Acc=0.85; Pre=0.86; Recall=0.85; F1=0.85; AUC OVR=0.95; AUC OVO=0.94\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 2 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 3\n",
      "Data Source: https://piyabute.com/data/research/letter-recognition.data.csv\n",
      "Preprocessing: Attribute = 17 [0E 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 15 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 20000\n",
      "Preprocessing: Class     = 26 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "Preprocessing: Train     = {0: 789, 1: 766, 2: 736, 3: 805, 4: 768, 5: 775, 6: 773, 7: 734, 8: 755, 9: 747, 10: 739, 11: 761, 12: 792, 13: 783, 14: 753, 15: 803, 16: 783, 17: 758, 18: 748, 19: 796, 20: 813, 21: 764, 22: 752, 23: 787, 24: 786, 25: 734}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 368.61 seconds / Size = 6044 / Original = 20000 / Remain = 13956\n",
      "Reduction: Level 2 is constructed. / Time = 178.14 seconds / Size = 3984 / Original = 13956 / Remain = 9972\n",
      "Reduction: Level 3 is constructed. / Time = 90.45 seconds / Size = 2585 / Original = 9972 / Remain = 7387\n",
      "Reduction: Level 4 is constructed. / Time = 24.76 seconds / Size = 1730 / Original = 7387 / Remain = 5657\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=3; sample=20000 (100.00%) {0: 789, 1: 766, 2: 736, 3: 805, 4: 768, 5: 775, 6: 773, 7: 734, 8: 755, 9: 747, 10: 739, 11: 761, 12: 792, 13: 783, 14: 753, 15: 803, 16: 783, 17: 758, 18: 748, 19: 796, 20: 813, 21: 764, 22: 752, 23: 787, 24: 786, 25: 734}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=20000; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=3; sample=1401 (7.00%) {0: 28, 1: 77, 2: 37, 3: 115, 4: 66, 5: 41, 6: 65, 7: 1, 8: 19, 9: 34, 10: 154, 11: 26, 12: 51, 13: 73, 14: 77, 15: 42, 16: 46, 17: 102, 18: 58, 19: 25, 20: 64, 21: 32, 22: 33, 23: 76, 24: 31, 25: 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=1401; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=3; sample=19213 (96.06%) {0: 785, 1: 732, 2: 717, 3: 777, 4: 733, 5: 742, 6: 742, 7: 650, 8: 726, 9: 716, 10: 673, 11: 742, 12: 776, 13: 748, 14: 734, 15: 753, 16: 756, 17: 696, 18: 730, 19: 775, 20: 802, 21: 727, 22: 733, 23: 753, 24: 769, 25: 726}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=19213; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=3; sample=19213 (96.06%) {0: 785, 1: 732, 2: 717, 3: 777, 4: 733, 5: 742, 6: 742, 7: 650, 8: 726, 9: 716, 10: 673, 11: 742, 12: 776, 13: 748, 14: 734, 15: 753, 16: 756, 17: 696, 18: 730, 19: 775, 20: 802, 21: 727, 22: 733, 23: 753, 24: 769, 25: 726}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=19213; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=3; sample=19242 (96.21%) {0: 786, 1: 719, 2: 714, 3: 772, 4: 724, 5: 730, 6: 738, 7: 663, 8: 730, 9: 725, 10: 674, 11: 744, 12: 779, 13: 755, 14: 723, 15: 764, 16: 754, 17: 699, 18: 736, 19: 776, 20: 798, 21: 739, 22: 741, 23: 758, 24: 773, 25: 728}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=19242; Acc=0.97; Pre=0.97; Recall=0.97; F1=0.97; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 5 TL; set=3; sample=19792 (98.96%) {0: 788, 1: 755, 2: 732, 3: 795, 4: 756, 5: 765, 6: 764, 7: 712, 8: 745, 9: 738, 10: 717, 11: 757, 12: 792, 13: 777, 14: 743, 15: 792, 16: 776, 17: 744, 18: 747, 19: 793, 20: 809, 21: 753, 22: 750, 23: 782, 24: 778, 25: 732}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=19792; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=3; sample=16398 (81.99%) {0: 426, 1: 754, 2: 660, 3: 796, 4: 737, 5: 510, 6: 746, 7: 1, 8: 538, 9: 593, 10: 722, 11: 689, 12: 716, 13: 730, 14: 707, 15: 631, 16: 701, 17: 734, 18: 703, 19: 728, 20: 769, 21: 430, 22: 657, 23: 676, 24: 660, 25: 384}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=16398; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=3; sample=19213 (96.06%) {0: 785, 1: 732, 2: 717, 3: 777, 4: 733, 5: 742, 6: 742, 7: 650, 8: 726, 9: 716, 10: 673, 11: 742, 12: 776, 13: 748, 14: 734, 15: 753, 16: 756, 17: 696, 18: 730, 19: 775, 20: 802, 21: 727, 22: 733, 23: 753, 24: 769, 25: 726}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=19213; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=3; sample=19084 (95.42%) {0: 734, 1: 734, 2: 734, 3: 734, 4: 734, 5: 734, 6: 734, 7: 734, 8: 734, 9: 734, 10: 734, 11: 734, 12: 734, 13: 734, 14: 734, 15: 734, 16: 734, 17: 734, 18: 734, 19: 734, 20: 734, 21: 734, 22: 734, 23: 734, 24: 734, 25: 734}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=19084; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=3; sample=19084 (95.42%) {0: 734, 1: 734, 2: 734, 3: 734, 4: 734, 5: 734, 6: 734, 7: 734, 8: 734, 9: 734, 10: 734, 11: 734, 12: 734, 13: 734, 14: 734, 15: 734, 16: 734, 17: 734, 18: 734, 19: 734, 20: 734, 21: 734, 22: 734, 23: 734, 24: 734, 25: 734}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=19084; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 10 NM$_3$; set=3; sample=6803 (34.02%) {0: 140, 1: 312, 2: 170, 3: 329, 4: 301, 5: 192, 6: 272, 7: 733, 8: 190, 9: 147, 10: 362, 11: 149, 12: 263, 13: 348, 14: 361, 15: 184, 16: 255, 17: 333, 18: 267, 19: 129, 20: 270, 21: 143, 22: 169, 23: 369, 24: 167, 25: 248}\n",
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=6803; Acc=0.87; Pre=0.88; Recall=0.87; F1=0.87; AUC OVR=0.98; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=3; sample=19120 (95.60%) {0: 734, 1: 734, 2: 734, 3: 736, 4: 740, 5: 734, 6: 737, 7: 734, 8: 734, 9: 737, 10: 734, 11: 738, 12: 736, 13: 734, 14: 735, 15: 738, 16: 737, 17: 734, 18: 734, 19: 736, 20: 734, 21: 735, 22: 734, 23: 739, 24: 734, 25: 734}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=19120; Acc=0.97; Pre=0.97; Recall=0.97; F1=0.97; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (730) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (710) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (725) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (704) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (524) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (715) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (718) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (673) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (732) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (689) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (718) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (730) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (706) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (726) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (678) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (640) found smaller than n_clusters (734). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=3; sample=19084 (95.42%) {0: 734, 1: 734, 2: 734, 3: 734, 4: 734, 5: 734, 6: 734, 7: 734, 8: 734, 9: 734, 10: 734, 11: 734, 12: 734, 13: 734, 14: 734, 15: 734, 16: 734, 17: 734, 18: 734, 19: 734, 20: 734, 21: 734, 22: 734, 23: 734, 24: 734, 25: 734}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=19084; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=3; sample=19084 (95.42%) {0: 734, 1: 734, 2: 734, 3: 734, 4: 734, 5: 734, 6: 734, 7: 734, 8: 734, 9: 734, 10: 734, 11: 734, 12: 734, 13: 734, 14: 734, 15: 734, 16: 734, 17: 734, 18: 734, 19: 734, 20: 734, 21: 734, 22: 734, 23: 734, 24: 734, 25: 734}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=19084; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=3; sample=6044 (30.22%) {0: 123, 1: 303, 2: 217, 3: 272, 4: 354, 5: 290, 6: 341, 7: 405, 8: 152, 9: 127, 10: 302, 11: 97, 12: 85, 13: 262, 14: 347, 15: 192, 16: 208, 17: 280, 18: 211, 19: 216, 20: 151, 21: 247, 22: 97, 23: 284, 24: 280, 25: 201}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=3; sample=6044 (30.22%) {0: 123, 1: 303, 2: 217, 3: 272, 4: 354, 5: 290, 6: 341, 7: 405, 8: 152, 9: 127, 10: 302, 11: 97, 12: 85, 13: 262, 14: 347, 15: 192, 16: 208, 17: 280, 18: 211, 19: 216, 20: 151, 21: 247, 22: 97, 23: 284, 24: 280, 25: 201}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=6044; Acc=0.79; Pre=0.80; Recall=0.79; F1=0.79; AUC OVR=0.96; AUC OVO=0.96\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=3; sample=10028 (50.14%) {0: 231, 1: 511, 2: 357, 3: 471, 4: 537, 5: 469, 6: 562, 7: 556, 8: 257, 9: 221, 10: 473, 11: 165, 12: 153, 13: 463, 14: 561, 15: 311, 16: 348, 17: 465, 18: 397, 19: 360, 20: 265, 21: 423, 22: 170, 23: 497, 24: 461, 25: 344}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=3; sample=10028 (50.14%) {0: 231, 1: 511, 2: 357, 3: 471, 4: 537, 5: 469, 6: 562, 7: 556, 8: 257, 9: 221, 10: 473, 11: 165, 12: 153, 13: 463, 14: 561, 15: 311, 16: 348, 17: 465, 18: 397, 19: 360, 20: 265, 21: 423, 22: 170, 23: 497, 24: 461, 25: 344}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=10028; Acc=0.89; Pre=0.89; Recall=0.89; F1=0.89; AUC OVR=0.98; AUC OVO=0.98\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=3; sample=12613 (63.07%) {0: 320, 1: 627, 2: 487, 3: 597, 4: 618, 5: 570, 6: 689, 7: 626, 8: 331, 9: 306, 10: 565, 11: 229, 12: 211, 13: 592, 14: 676, 15: 398, 16: 443, 17: 575, 18: 513, 19: 454, 20: 349, 21: 552, 22: 241, 23: 637, 24: 577, 25: 430}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=3; sample=12613 (63.07%) {0: 320, 1: 627, 2: 487, 3: 597, 4: 618, 5: 570, 6: 689, 7: 626, 8: 331, 9: 306, 10: 565, 11: 229, 12: 211, 13: 592, 14: 676, 15: 398, 16: 443, 17: 575, 18: 513, 19: 454, 20: 349, 21: 552, 22: 241, 23: 637, 24: 577, 25: 430}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=12613; Acc=0.92; Pre=0.92; Recall=0.92; F1=0.92; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=3; sample=14343 (71.71%) {0: 387, 1: 699, 2: 575, 3: 677, 4: 659, 5: 615, 6: 749, 7: 659, 8: 396, 9: 360, 10: 618, 11: 276, 12: 283, 13: 675, 14: 735, 15: 462, 16: 529, 17: 637, 18: 580, 19: 533, 20: 421, 21: 642, 22: 314, 23: 705, 24: 659, 25: 498}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=3; sample=14343 (71.71%) {0: 387, 1: 699, 2: 575, 3: 677, 4: 659, 5: 615, 6: 749, 7: 659, 8: 396, 9: 360, 10: 618, 11: 276, 12: 283, 13: 675, 14: 735, 15: 462, 16: 529, 17: 637, 18: 580, 19: 533, 20: 421, 21: 642, 22: 314, 23: 705, 24: 659, 25: 498}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=14343; Acc=0.93; Pre=0.93; Recall=0.93; F1=0.93; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 3 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 4\n",
      "Data Source: https://piyabute.com/data/research/optdigits.custom.csv\n",
      "Preprocessing: Attribute = 65 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64E ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 42 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 5620\n",
      "Preprocessing: Class     = 10 [0 1 2 3 4 5 6 7 8 9]\n",
      "Preprocessing: Train     = {0: 554, 1: 571, 2: 557, 3: 572, 4: 568, 5: 558, 6: 558, 7: 566, 8: 554, 9: 562}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 27.57 seconds / Size = 1735 / Original = 5620 / Remain = 3885\n",
      "Reduction: Level 2 is constructed. / Time = 12.84 seconds / Size = 1404 / Original = 3885 / Remain = 2481\n",
      "Reduction: Level 3 is constructed. / Time = 2.68 seconds / Size = 940 / Original = 2481 / Remain = 1541\n",
      "Reduction: Level 4 is constructed. / Time = 1.10 seconds / Size = 607 / Original = 1541 / Remain = 934\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=4; sample=5620 (100.00%) {0: 554, 1: 571, 2: 557, 3: 572, 4: 568, 5: 558, 6: 558, 7: 566, 8: 554, 9: 562}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=5620; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=4; sample=272 (4.84%) {0: 1, 1: 15, 2: 18, 3: 25, 4: 21, 5: 39, 6: 22, 7: 20, 8: 54, 9: 57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=272; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=4; sample=5522 (98.26%) {0: 553, 1: 567, 2: 556, 3: 561, 4: 558, 5: 548, 6: 554, 7: 562, 8: 517, 9: 546}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=5522; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=4; sample=5522 (98.26%) {0: 553, 1: 567, 2: 556, 3: 561, 4: 558, 5: 548, 6: 554, 7: 562, 8: 517, 9: 546}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=5522; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=4; sample=5523 (98.27%) {0: 552, 1: 567, 2: 554, 3: 562, 4: 562, 5: 547, 6: 556, 7: 561, 8: 520, 9: 542}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=5523; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 5 TL; set=4; sample=5612 (99.86%) {0: 554, 1: 570, 2: 556, 3: 571, 4: 568, 5: 557, 6: 558, 7: 566, 8: 553, 9: 559}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=5612; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=4; sample=3551 (63.19%) {0: 1, 1: 284, 2: 407, 3: 428, 4: 519, 5: 423, 6: 395, 7: 138, 8: 513, 9: 443}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=3551; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=4; sample=5522 (98.26%) {0: 553, 1: 567, 2: 556, 3: 561, 4: 558, 5: 548, 6: 554, 7: 562, 8: 517, 9: 546}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=5522; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=4; sample=5540 (98.58%) {0: 554, 1: 554, 2: 554, 3: 554, 4: 554, 5: 554, 6: 554, 7: 554, 8: 554, 9: 554}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=5540; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=4; sample=5540 (98.58%) {0: 554, 1: 554, 2: 554, 3: 554, 4: 554, 5: 554, 6: 554, 7: 554, 8: 554, 9: 554}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=5540; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 10 NM$_3$; set=4; sample=2359 (41.98%) {0: 554, 1: 181, 2: 177, 3: 222, 4: 176, 5: 196, 6: 213, 7: 181, 8: 227, 9: 232}\n",
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=2359; Acc=0.97; Pre=0.97; Recall=0.97; F1=0.97; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=4; sample=5546 (98.68%) {0: 554, 1: 555, 2: 554, 3: 556, 4: 555, 5: 554, 6: 554, 7: 555, 8: 554, 9: 555}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=5546; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=4; sample=5540 (98.58%) {0: 554, 1: 554, 2: 554, 3: 554, 4: 554, 5: 554, 6: 554, 7: 554, 8: 554, 9: 554}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=5540; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=4; sample=5540 (98.58%) {0: 554, 1: 554, 2: 554, 3: 554, 4: 554, 5: 554, 6: 554, 7: 554, 8: 554, 9: 554}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=5540; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=4; sample=1735 (30.87%) {0: 142, 1: 223, 2: 90, 3: 292, 4: 102, 5: 164, 6: 129, 7: 95, 8: 191, 9: 307}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=4; sample=1735 (30.87%) {0: 142, 1: 223, 2: 90, 3: 292, 4: 102, 5: 164, 6: 129, 7: 95, 8: 191, 9: 307}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=1735; Acc=0.92; Pre=0.93; Recall=0.92; F1=0.92; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=4; sample=3139 (55.85%) {0: 303, 1: 408, 2: 182, 3: 467, 4: 221, 5: 303, 6: 263, 7: 190, 8: 345, 9: 457}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=4; sample=3139 (55.85%) {0: 303, 1: 408, 2: 182, 3: 467, 4: 221, 5: 303, 6: 263, 7: 190, 8: 345, 9: 457}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=3139; Acc=0.96; Pre=0.97; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=4; sample=4079 (72.58%) {0: 455, 1: 487, 2: 266, 3: 541, 4: 307, 5: 416, 6: 371, 7: 271, 8: 447, 9: 518}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=4; sample=4079 (72.58%) {0: 455, 1: 487, 2: 266, 3: 541, 4: 307, 5: 416, 6: 371, 7: 271, 8: 447, 9: 518}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=4079; Acc=0.97; Pre=0.98; Recall=0.97; F1=0.97; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=4; sample=4686 (83.38%) {0: 523, 1: 517, 2: 346, 3: 564, 4: 385, 5: 495, 6: 451, 7: 351, 8: 510, 9: 544}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=4; sample=4686 (83.38%) {0: 523, 1: 517, 2: 346, 3: 564, 4: 385, 5: 495, 6: 451, 7: 351, 8: 510, 9: 544}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=4686; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 4 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 5\n",
      "Data Source: https://piyabute.com/data/research/pendigits.custom.csv\n",
      "Preprocessing: Attribute = 17 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16E ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 13 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 10992\n",
      "Preprocessing: Class     = 10 [0 1 2 3 4 5 6 7 8 9]\n",
      "Preprocessing: Train     = {0: 1143, 1: 1143, 2: 1144, 3: 1055, 4: 1144, 5: 1055, 6: 1056, 7: 1142, 8: 1055, 9: 1055}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 102.63 seconds / Size = 1475 / Original = 10992 / Remain = 9517\n",
      "Reduction: Level 2 is constructed. / Time = 39.50 seconds / Size = 1506 / Original = 9517 / Remain = 8011\n",
      "Reduction: Level 3 is constructed. / Time = 27.67 seconds / Size = 1320 / Original = 8011 / Remain = 6691\n",
      "Reduction: Level 4 is constructed. / Time = 19.43 seconds / Size = 1169 / Original = 6691 / Remain = 5522\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=5; sample=10992 (100.00%) {0: 1143, 1: 1143, 2: 1144, 3: 1055, 4: 1144, 5: 1055, 6: 1056, 7: 1142, 8: 1055, 9: 1055}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=10992; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=5; sample=108 (0.98%) {0: 14, 1: 19, 2: 5, 3: 6, 4: 4, 5: 22, 6: 7, 7: 20, 8: 1, 9: 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=108; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=5; sample=10930 (99.44%) {0: 1137, 1: 1128, 2: 1143, 3: 1049, 4: 1142, 5: 1046, 6: 1055, 7: 1138, 8: 1048, 9: 1044}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=10930; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=5; sample=10930 (99.44%) {0: 1137, 1: 1128, 2: 1143, 3: 1049, 4: 1142, 5: 1046, 6: 1055, 7: 1138, 8: 1048, 9: 1044}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=10930; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=5; sample=10933 (99.46%) {0: 1138, 1: 1133, 2: 1140, 3: 1048, 4: 1142, 5: 1047, 6: 1055, 7: 1134, 8: 1050, 9: 1046}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=10933; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 5 TL; set=5; sample=10984 (99.93%) {0: 1142, 1: 1143, 2: 1143, 3: 1054, 4: 1144, 5: 1055, 6: 1056, 7: 1140, 8: 1053, 9: 1054}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=10984; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=5; sample=3588 (32.64%) {0: 881, 1: 642, 2: 96, 3: 53, 4: 107, 5: 645, 6: 346, 7: 521, 9: 297}\n",
      "Training: Cannot maintain all class labels!\n",
      "Training: Type OSS; cv=5; d=4; k=[1-9]; Train=3588; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=5; sample=10930 (99.44%) {0: 1137, 1: 1128, 2: 1143, 3: 1049, 4: 1142, 5: 1046, 6: 1055, 7: 1138, 8: 1048, 9: 1044}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=10930; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=5; sample=10550 (95.98%) {0: 1055, 1: 1055, 2: 1055, 3: 1055, 4: 1055, 5: 1055, 6: 1055, 7: 1055, 8: 1055, 9: 1055}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=10550; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=5; sample=10550 (95.98%) {0: 1055, 1: 1055, 2: 1055, 3: 1055, 4: 1055, 5: 1055, 6: 1055, 7: 1055, 8: 1055, 9: 1055}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=10550; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 10 NM$_3$; set=5; sample=3048 (27.73%) {0: 266, 1: 239, 2: 179, 3: 212, 4: 221, 5: 225, 6: 200, 7: 182, 8: 1055, 9: 269}\n",
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=3048; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=5; sample=10562 (96.09%) {0: 1056, 1: 1060, 2: 1055, 3: 1055, 4: 1061, 5: 1055, 6: 1055, 7: 1055, 8: 1055, 9: 1055}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=10562; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=5; sample=10550 (95.98%) {0: 1055, 1: 1055, 2: 1055, 3: 1055, 4: 1055, 5: 1055, 6: 1055, 7: 1055, 8: 1055, 9: 1055}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=10550; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=5; sample=10550 (95.98%) {0: 1055, 1: 1055, 2: 1055, 3: 1055, 4: 1055, 5: 1055, 6: 1055, 7: 1055, 8: 1055, 9: 1055}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=10550; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=5; sample=1475 (13.42%) {0: 107, 1: 246, 2: 191, 3: 130, 4: 118, 5: 224, 6: 85, 7: 139, 8: 81, 9: 154}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=5; sample=1475 (13.42%) {0: 107, 1: 246, 2: 191, 3: 130, 4: 118, 5: 224, 6: 85, 7: 139, 8: 81, 9: 154}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=1475; Acc=0.89; Pre=0.89; Recall=0.89; F1=0.88; AUC OVR=0.98; AUC OVO=0.98\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=5; sample=2981 (27.12%) {0: 228, 1: 456, 2: 376, 3: 249, 4: 259, 5: 435, 6: 184, 7: 303, 8: 172, 9: 319}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=5; sample=2981 (27.12%) {0: 228, 1: 456, 2: 376, 3: 249, 4: 259, 5: 435, 6: 184, 7: 303, 8: 172, 9: 319}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=2981; Acc=0.97; Pre=0.97; Recall=0.97; F1=0.97; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=5; sample=4301 (39.13%) {0: 366, 1: 618, 2: 511, 3: 375, 4: 375, 5: 592, 6: 283, 7: 466, 8: 262, 9: 453}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=5; sample=4301 (39.13%) {0: 366, 1: 618, 2: 511, 3: 375, 4: 375, 5: 592, 6: 283, 7: 466, 8: 262, 9: 453}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=4301; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=5; sample=5470 (49.76%) {0: 491, 1: 736, 2: 645, 3: 490, 4: 480, 5: 697, 6: 388, 7: 608, 8: 350, 9: 585}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=5; sample=5470 (49.76%) {0: 491, 1: 736, 2: 645, 3: 490, 4: 480, 5: 697, 6: 388, 7: 608, 8: 350, 9: 585}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=5470; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 5 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 6\n",
      "Data Source: https://piyabute.com/data/research/statlog_landsat.custom.csv\n",
      "Preprocessing: Attribute = 37 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36E ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 16 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 6435\n",
      "Preprocessing: Class     = 6 [0 1 2 3 4 5]\n",
      "Preprocessing: Train     = {0: 1533, 1: 703, 2: 1358, 3: 626, 4: 707, 5: 1508}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 19.47 seconds / Size = 1647 / Original = 6435 / Remain = 4788\n",
      "Reduction: Level 2 is constructed. / Time = 8.57 seconds / Size = 869 / Original = 4788 / Remain = 3919\n",
      "Reduction: Level 3 is constructed. / Time = 5.51 seconds / Size = 523 / Original = 3919 / Remain = 3396\n",
      "Reduction: Level 4 is constructed. / Time = 3.99 seconds / Size = 458 / Original = 3396 / Remain = 2938\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=6; sample=6435 (100.00%) {0: 1533, 1: 703, 2: 1358, 3: 626, 4: 707, 5: 1508}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=6435; Acc=0.88; Pre=0.89; Recall=0.88; F1=0.88; AUC OVR=0.97; AUC OVO=0.96\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=6; sample=1016 (15.79%) {0: 96, 1: 43, 2: 363, 3: 1, 4: 123, 5: 390}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=1016; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=6; sample=5702 (88.61%) {0: 1489, 1: 685, 2: 1243, 3: 411, 4: 566, 5: 1308}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=5702; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=6; sample=5702 (88.61%) {0: 1489, 1: 685, 2: 1243, 3: 411, 4: 566, 5: 1308}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=5702; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=6; sample=5626 (87.43%) {0: 1480, 1: 682, 2: 1195, 3: 412, 4: 581, 5: 1276}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=5626; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 5 TL; set=6; sample=6217 (96.61%) {0: 1527, 1: 695, 2: 1307, 3: 555, 4: 683, 5: 1450}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=6217; Acc=0.90; Pre=0.90; Recall=0.90; F1=0.90; AUC OVR=0.97; AUC OVO=0.97\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=6; sample=5074 (78.85%) {0: 1200, 1: 447, 2: 1335, 3: 1, 4: 678, 5: 1413}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=5074; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=6; sample=5702 (88.61%) {0: 1489, 1: 685, 2: 1243, 3: 411, 4: 566, 5: 1308}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=5702; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.96; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=6; sample=3756 (58.37%) {0: 626, 1: 626, 2: 626, 3: 626, 4: 626, 5: 626}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=3756; Acc=0.86; Pre=0.87; Recall=0.86; F1=0.86; AUC OVR=0.96; AUC OVO=0.96\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=6; sample=3756 (58.37%) {0: 626, 1: 626, 2: 626, 3: 626, 4: 626, 5: 626}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=3756; Acc=0.87; Pre=0.88; Recall=0.87; F1=0.87; AUC OVR=0.96; AUC OVO=0.96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 10 NM$_3$; set=6; sample=1844 (28.66%) {0: 147, 1: 44, 2: 380, 3: 626, 4: 180, 5: 467}\n",
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=1844; Acc=0.67; Pre=0.68; Recall=0.67; F1=0.67; AUC OVR=0.85; AUC OVO=0.87\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=6; sample=3791 (58.91%) {0: 649, 1: 626, 2: 637, 3: 626, 4: 627, 5: 626}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=3791; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=6; sample=3756 (58.37%) {0: 626, 1: 626, 2: 626, 3: 626, 4: 626, 5: 626}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=3756; Acc=0.83; Pre=0.84; Recall=0.83; F1=0.83; AUC OVR=0.95; AUC OVO=0.95\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=6; sample=3756 (58.37%) {0: 626, 1: 626, 2: 626, 3: 626, 4: 626, 5: 626}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=3756; Acc=0.89; Pre=0.89; Recall=0.89; F1=0.89; AUC OVR=0.97; AUC OVO=0.97\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=6; sample=1647 (25.59%) {0: 73, 1: 34, 2: 243, 3: 450, 4: 291, 5: 556}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=6; sample=1663 (25.84%) {0: 73, 1: 50, 2: 243, 3: 450, 4: 291, 5: 556}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=1663; Acc=0.60; Pre=0.61; Recall=0.60; F1=0.60; AUC OVR=0.83; AUC OVO=0.84\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=6; sample=2516 (39.10%) {0: 132, 1: 44, 2: 376, 3: 583, 4: 475, 5: 906}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=6; sample=2522 (39.19%) {0: 132, 1: 50, 2: 376, 3: 583, 4: 475, 5: 906}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=2522; Acc=0.70; Pre=0.72; Recall=0.70; F1=0.70; AUC OVR=0.88; AUC OVO=0.88\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=6; sample=3039 (47.23%) {0: 187, 1: 50, 2: 470, 3: 619, 4: 563, 5: 1150}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=6; sample=3039 (47.23%) {0: 187, 1: 50, 2: 470, 3: 619, 4: 563, 5: 1150}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=3039; Acc=0.74; Pre=0.75; Recall=0.74; F1=0.74; AUC OVR=0.90; AUC OVO=0.90\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=6; sample=3497 (54.34%) {0: 274, 1: 54, 2: 596, 3: 625, 4: 613, 5: 1335}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=6; sample=3497 (54.34%) {0: 274, 1: 54, 2: 596, 3: 625, 4: 613, 5: 1335}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=3497; Acc=0.78; Pre=0.79; Recall=0.78; F1=0.78; AUC OVR=0.92; AUC OVO=0.91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 6 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 7\n",
      "Data Source: https://piyabute.com/data/research/tic-tac-toe.data.csv\n",
      "Preprocessing: Attribute = 10 [0E 1E 2E 3E 4E 5E 6E 7E 8E 9E ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 9 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 958\n",
      "Preprocessing: Class     = 2 [0 1]\n",
      "Preprocessing: Train     = {0: 332, 1: 626}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 0.48 seconds / Size = 443 / Original = 958 / Remain = 515\n",
      "Reduction: Level 2 is constructed. / Time = 0.18 seconds / Size = 160 / Original = 515 / Remain = 355\n",
      "Reduction: Level 3 is constructed. / Time = 0.17 seconds / Size = 55 / Original = 355 / Remain = 300\n",
      "Reduction: Level 4 is constructed. / Time = 0.12 seconds / Size = 4 / Original = 300 / Remain = 296\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=7; sample=958 (100.00%) {0: 332, 1: 626}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=958; Acc=0.85; Pre=0.88; Recall=0.85; F1=0.84; AUC OVR=0.90; AUC OVO=0.90\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=7; sample=144 (15.03%) {0: 1, 1: 143}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=144; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=7; sample=845 (88.20%) {0: 220, 1: 625}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=845; Acc=0.95; Pre=0.96; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=7; sample=845 (88.20%) {0: 220, 1: 625}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=845; Acc=0.95; Pre=0.96; Recall=0.95; F1=0.95; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=7; sample=837 (87.37%) {0: 220, 1: 617}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=837; Acc=0.96; Pre=0.96; Recall=0.96; F1=0.95; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 5 TL; set=7; sample=952 (99.37%) {0: 329, 1: 623}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=952; Acc=0.86; Pre=0.88; Recall=0.86; F1=0.85; AUC OVR=0.89; AUC OVO=0.89\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=7; sample=617 (64.41%) {0: 1, 1: 616}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=617; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=7; sample=567 (59.19%) {0: 220, 1: 347}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=567; Acc=0.95; Pre=0.95; Recall=0.95; F1=0.95; AUC OVR=0.98; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=7; sample=664 (69.31%) {0: 332, 1: 332}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=664; Acc=0.83; Pre=0.85; Recall=0.83; F1=0.83; AUC OVR=0.89; AUC OVO=0.89\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=7; sample=664 (69.31%) {0: 332, 1: 332}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=664; Acc=0.87; Pre=0.88; Recall=0.87; F1=0.87; AUC OVR=0.94; AUC OVO=0.94\n",
      "\n",
      "Training: (Post) Type 10 NM$_3$; set=7; sample=664 (69.31%) {0: 332, 1: 332}\n",
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=664; Acc=0.84; Pre=0.86; Recall=0.84; F1=0.84; AUC OVR=0.90; AUC OVO=0.90\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=7; sample=719 (75.05%) {0: 332, 1: 387}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=719; Acc=0.86; Pre=0.88; Recall=0.86; F1=0.86; AUC OVR=0.91; AUC OVO=0.91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=7; sample=664 (69.31%) {0: 332, 1: 332}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=664; Acc=0.84; Pre=0.85; Recall=0.84; F1=0.84; AUC OVR=0.90; AUC OVO=0.90\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=7; sample=664 (69.31%) {0: 332, 1: 332}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=664; Acc=0.82; Pre=0.82; Recall=0.82; F1=0.82; AUC OVR=0.88; AUC OVO=0.88\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=7; sample=443 (46.24%) {0: 224, 1: 219}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=7; sample=443 (46.24%) {0: 224, 1: 219}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=443; Acc=0.72; Pre=0.73; Recall=0.72; F1=0.72; AUC OVR=0.76; AUC OVO=0.76\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=7; sample=603 (62.94%) {0: 300, 1: 303}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=7; sample=603 (62.94%) {0: 300, 1: 303}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=603; Acc=0.75; Pre=0.76; Recall=0.75; F1=0.75; AUC OVR=0.82; AUC OVO=0.82\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=7; sample=658 (68.68%) {0: 330, 1: 328}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=7; sample=658 (68.68%) {0: 330, 1: 328}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=658; Acc=0.81; Pre=0.82; Recall=0.81; F1=0.81; AUC OVR=0.88; AUC OVO=0.88\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=7; sample=662 (69.10%) {0: 332, 1: 330}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=7; sample=662 (69.10%) {0: 332, 1: 330}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=662; Acc=0.81; Pre=0.82; Recall=0.81; F1=0.80; AUC OVR=0.87; AUC OVO=0.87\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 7 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 8\n",
      "Data Source: https://piyabute.com/data/research/TUANDROMD.csv\n",
      "Preprocessing: Attribute = 242 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241E ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 66 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 4464\n",
      "Preprocessing: Class     = 2 [0 1]\n",
      "Preprocessing: Train     = {0: 899, 1: 3565}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 6.81 seconds / Size = 159 / Original = 4464 / Remain = 4305\n",
      "Reduction: Level 2 is constructed. / Time = 5.88 seconds / Size = 133 / Original = 4305 / Remain = 4172\n",
      "Reduction: Level 3 is constructed. / Time = 5.53 seconds / Size = 105 / Original = 4172 / Remain = 4067\n",
      "Reduction: Level 4 is constructed. / Time = 4.99 seconds / Size = 96 / Original = 4067 / Remain = 3971\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=8; sample=4464 (100.00%) {0: 899, 1: 3565}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=4464; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=0.98; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=8; sample=73 (1.64%) {0: 1, 1: 72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=73; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=8; sample=4407 (98.72%) {0: 868, 1: 3539}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=4407; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=8; sample=4405 (98.68%) {0: 867, 1: 3538}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=4405; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=8; sample=4348 (97.40%) {0: 801, 1: 3547}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=4348; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 5 TL; set=8; sample=4464 (100.00%) {0: 899, 1: 3565}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=4464; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=0.98; AUC OVO=0.98\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=8; sample=1214 (27.20%) {0: 1, 1: 1213}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=1214; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=8; sample=4351 (97.47%) {0: 868, 1: 3483}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=4351; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=8; sample=1798 (40.28%) {0: 899, 1: 899}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=1798; Acc=0.97; Pre=0.98; Recall=0.97; F1=0.97; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=8; sample=1798 (40.28%) {0: 899, 1: 899}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=1798; Acc=1.00; Pre=1.00; Recall=1.00; F1=1.00; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n",
      "Training: (Post) Type 10 NM$_3$; set=8; sample=1067 (23.90%) {0: 825, 1: 242}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=1067; Acc=0.94; Pre=0.94; Recall=0.94; F1=0.94; AUC OVR=0.97; AUC OVO=0.97\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=8; sample=4246 (95.12%) {0: 899, 1: 3347}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=4246; Acc=0.99; Pre=0.99; Recall=0.99; F1=0.99; AUC OVR=1.00; AUC OVO=1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (543) found smaller than n_clusters (899). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:190: ConvergenceWarning: Number of distinct clusters (481) found smaller than n_clusters (899). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=8; sample=1798 (40.28%) {0: 899, 1: 899}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=1798; Acc=0.98; Pre=0.98; Recall=0.98; F1=0.98; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=8; sample=1798 (40.28%) {0: 899, 1: 899}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=1798; Acc=0.97; Pre=0.97; Recall=0.97; F1=0.97; AUC OVR=0.99; AUC OVO=0.99\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=8; sample=159 (3.56%) {0: 68, 1: 91}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=8; sample=159 (3.56%) {0: 68, 1: 91}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=159; Acc=0.78; Pre=0.80; Recall=0.78; F1=0.78; AUC OVR=0.85; AUC OVO=0.85\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=8; sample=292 (6.54%) {0: 122, 1: 170}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=8; sample=292 (6.54%) {0: 122, 1: 170}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=292; Acc=0.85; Pre=0.86; Recall=0.85; F1=0.85; AUC OVR=0.92; AUC OVO=0.92\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=8; sample=397 (8.89%) {0: 157, 1: 240}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=8; sample=397 (8.89%) {0: 157, 1: 240}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=397; Acc=0.87; Pre=0.88; Recall=0.87; F1=0.87; AUC OVR=0.93; AUC OVO=0.93\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=8; sample=493 (11.04%) {0: 194, 1: 299}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=8; sample=493 (11.04%) {0: 194, 1: 299}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=493; Acc=0.89; Pre=0.90; Recall=0.89; F1=0.89; AUC OVR=0.95; AUC OVO=0.95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 8 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Dataset: 9\n",
      "Data Source: https://piyabute.com/data/research/waveform-+noise.v2.data.csv\n",
      "Preprocessing: Attribute = 41 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40E ] (LabelEncoding)\n",
      "Preprocessing: Attribute = 40 (PCA) (Norm)\n",
      "Preprocessing: Sample    = 5000\n",
      "Preprocessing: Class     = 3 [0 1 2]\n",
      "Preprocessing: Train     = {0: 1692, 1: 1653, 2: 1655}\n",
      "Reduction begins...\n",
      "Reduction: Level 1 is constructed. / Time = 16.60 seconds / Size = 2047 / Original = 5000 / Remain = 2953\n",
      "Reduction: Level 2 is constructed. / Time = 2.90 seconds / Size = 1406 / Original = 2953 / Remain = 1547\n",
      "Reduction: Level 3 is constructed. / Time = 0.97 seconds / Size = 798 / Original = 1547 / Remain = 749\n",
      "Reduction: Level 4 is constructed. / Time = 0.34 seconds / Size = 395 / Original = 749 / Remain = 354\n",
      "Training:\n",
      "Training: (Post) Type 0 ORG; set=9; sample=5000 (100.00%) {0: 1692, 1: 1653, 2: 1655}\n",
      "Training: Type ORG; cv=5; d=4; k=[1-9]; Train=5000; Acc=0.70; Pre=0.70; Recall=0.70; F1=0.70; AUC OVR=0.85; AUC OVO=0.85\n",
      "\n",
      "Training: (Post) Type 1 CNN; set=9; sample=1272 (25.44%) {0: 681, 1: 1, 2: 590}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type CNN; cv=2; d=4; k=[1-9]; Train=1272; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 2 ENN; set=9; sample=3383 (67.66%) {0: 1146, 1: 1124, 2: 1113}\n",
      "Training: Type ENN; cv=5; d=4; k=[1-9]; Train=3383; Acc=0.86; Pre=0.86; Recall=0.86; F1=0.86; AUC OVR=0.94; AUC OVO=0.94\n",
      "\n",
      "Training: (Post) Type 3 RENN; set=9; sample=3383 (67.66%) {0: 1146, 1: 1124, 2: 1113}\n",
      "Training: Type RENN; cv=5; d=4; k=[1-9]; Train=3383; Acc=0.86; Pre=0.86; Recall=0.86; F1=0.86; AUC OVR=0.94; AUC OVO=0.94\n",
      "\n",
      "Training: (Post) Type 4 All KNN; set=9; sample=3150 (63.00%) {0: 1029, 1: 1082, 2: 1039}\n",
      "Training: Type All KNN; cv=5; d=4; k=[1-9]; Train=3150; Acc=0.83; Pre=0.83; Recall=0.83; F1=0.83; AUC OVR=0.93; AUC OVO=0.93\n",
      "\n",
      "Training: (Post) Type 5 TL; set=9; sample=4660 (93.20%) {0: 1572, 1: 1550, 2: 1538}\n",
      "Training: Type TL; cv=5; d=4; k=[1-9]; Train=4660; Acc=0.72; Pre=0.72; Recall=0.72; F1=0.72; AUC OVR=0.86; AUC OVO=0.86\n",
      "\n",
      "Training: (Post) Type 6 OSS; set=9; sample=3147 (62.94%) {0: 1609, 1: 1, 2: 1537}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Type OSS; cv=2; d=4; k=[1-9]; Train=3147; Acc=nan; Pre=nan; Recall=nan; F1=nan; AUC OVR=nan; AUC OVO=nan\n",
      "\n",
      "Training: (Post) Type 7 NCL; set=9; sample=3383 (67.66%) {0: 1146, 1: 1124, 2: 1113}\n",
      "Training: Type NCL; cv=5; d=4; k=[1-9]; Train=3383; Acc=0.86; Pre=0.86; Recall=0.86; F1=0.86; AUC OVR=0.94; AUC OVO=0.94\n",
      "\n",
      "Training: (Post) Type 8 NM$_1$; set=9; sample=4959 (99.18%) {0: 1653, 1: 1653, 2: 1653}\n",
      "Training: Type NM$_1$; cv=5; d=4; k=[1-9]; Train=4959; Acc=0.70; Pre=0.70; Recall=0.70; F1=0.70; AUC OVR=0.85; AUC OVO=0.85\n",
      "\n",
      "Training: (Post) Type 9 NM$_2$; set=9; sample=4959 (99.18%) {0: 1653, 1: 1653, 2: 1653}\n",
      "Training: Type NM$_2$; cv=5; d=4; k=[1-9]; Train=4959; Acc=0.70; Pre=0.70; Recall=0.70; F1=0.70; AUC OVR=0.85; AUC OVO=0.85\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:188: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 10 NM$_3$; set=9; sample=3428 (68.56%) {0: 924, 1: 1653, 2: 851}\n",
      "Training: Type NM$_3$; cv=5; d=4; k=[1-9]; Train=3428; Acc=0.69; Pre=0.69; Recall=0.69; F1=0.69; AUC OVR=0.82; AUC OVO=0.83\n",
      "\n",
      "Training: (Post) Type 11 IHT; set=9; sample=4960 (99.20%) {0: 1654, 1: 1653, 2: 1653}\n",
      "Training: Type IHT; cv=5; d=4; k=[1-9]; Train=4960; Acc=0.70; Pre=0.71; Recall=0.70; F1=0.70; AUC OVR=0.85; AUC OVO=0.85\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:138: FutureWarning: 'n_jobs' was deprecated in 0.7 and will be removed in 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (Post) Type 12 CC; set=9; sample=4959 (99.18%) {0: 1653, 1: 1653, 2: 1653}\n",
      "Training: Type CC; cv=5; d=4; k=[1-9]; Train=4959; Acc=0.69; Pre=0.69; Recall=0.69; F1=0.69; AUC OVR=0.84; AUC OVO=0.84\n",
      "\n",
      "Training: (Post) Type 13 RUS; set=9; sample=4959 (99.18%) {0: 1653, 1: 1653, 2: 1653}\n",
      "Training: Type RUS; cv=5; d=4; k=[1-9]; Train=4959; Acc=0.77; Pre=0.77; Recall=0.77; F1=0.77; AUC OVR=0.90; AUC OVO=0.90\n",
      "\n",
      "Training: (Pre) Type 14 CCNN$_1$; set=9; sample=2047 (40.94%) {0: 704, 1: 663, 2: 680}\n",
      "Training: (Post) Type 14 CCNN$_1$; set=9; sample=2047 (40.94%) {0: 704, 1: 663, 2: 680}\n",
      "Training: Type CCNN$_1$; cv=5; d=4; k=[1-9]; Train=2047; Acc=0.60; Pre=0.61; Recall=0.60; F1=0.60; AUC OVR=0.78; AUC OVO=0.78\n",
      "\n",
      "Training: (Pre) Type 15 CCNN$_2$; set=9; sample=3453 (69.06%) {0: 1185, 1: 1148, 2: 1120}\n",
      "Training: (Post) Type 15 CCNN$_2$; set=9; sample=3453 (69.06%) {0: 1185, 1: 1148, 2: 1120}\n",
      "Training: Type CCNN$_2$; cv=5; d=4; k=[1-9]; Train=3453; Acc=0.66; Pre=0.66; Recall=0.66; F1=0.66; AUC OVR=0.83; AUC OVO=0.83\n",
      "\n",
      "Training: (Pre) Type 16 CCNN$_3$; set=9; sample=4251 (85.02%) {0: 1469, 1: 1411, 2: 1371}\n",
      "Training: (Post) Type 16 CCNN$_3$; set=9; sample=4251 (85.02%) {0: 1469, 1: 1411, 2: 1371}\n",
      "Training: Type CCNN$_3$; cv=5; d=4; k=[1-9]; Train=4251; Acc=0.68; Pre=0.68; Recall=0.68; F1=0.68; AUC OVR=0.84; AUC OVO=0.84\n",
      "\n",
      "Training: (Pre) Type 17 CCNN$_4$; set=9; sample=4646 (92.92%) {0: 1601, 1: 1544, 2: 1501}\n",
      "Training: (Post) Type 17 CCNN$_4$; set=9; sample=4646 (92.92%) {0: 1601, 1: 1544, 2: 1501}\n",
      "Training: Type CCNN$_4$; cv=5; d=4; k=[1-9]; Train=4646; Acc=0.69; Pre=0.69; Recall=0.69; F1=0.69; AUC OVR=0.84; AUC OVO=0.84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Dataset 9 is done!\n",
      "------------------------------------------------------------------------------\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Load numpy, pandas, and sklern library\n",
    "# https://numpy.org/devdocs/user/absolute_beginneencoder_rs.html\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "# https://matplotlib.org/stable/gallery/mplot3d/scatter3d.html\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import glob\n",
    "# File processing\n",
    "import sys\n",
    "# import scipy.spatial.distance as sc\n",
    "\n",
    "# Distance Calculation\n",
    "import math, statistics\n",
    "from scipy.spatial import distance\n",
    "\n",
    "#from chebyshev import Chebyshev\n",
    "import numpy.polynomial.chebyshev \n",
    "\n",
    "# Data Transformation\n",
    "# LabelEncoder = dummy coding\n",
    "# OneHotEncoder = unique integers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Baselines (Undersampling)\n",
    "# https://imbalanced-learn.org/\n",
    "# conda install -c conda-forge imbalanced-learn\n",
    "# pip install -U imbalanced-learn\n",
    "from imblearn.under_sampling import AllKNN\n",
    "from imblearn.under_sampling import ClusterCentroids \n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from imblearn.under_sampling import NearMiss \n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule \n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from imblearn.under_sampling import TomekLinks \n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold # train_test_split, GridSearchCV, cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold # train_test_split, GridSearchCV, cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedKFold # train_test_split, GridSearchCV, cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import KFold # train_test_split, GridSearchCV, cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Performance\n",
    "#from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score\n",
    "\n",
    "# Complexity\n",
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "# Multiprocessing\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "if (num_cores > 20):\n",
    "    num_cores -= 4\n",
    "# num_cores = 24\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# DATA REDUCTION FUNCTION\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/spatial.distance.html\n",
    "d_name = ('Cityblock','Chebyshev','Correlation','Cosine','Euclidean')\n",
    "def find_minimum_distance(d,i):\n",
    "    min_dist = 999999999999999.0\n",
    "    min_vec = -1\n",
    "    if (d == 0): # Cityblock\n",
    "        for j in range(tempdata.shape[0]):\n",
    "            if (templabel[i] != templabel[j]):\n",
    "#                new_dist = distance.cityblock(tempdata[i],tempdata[j])\n",
    "                new_dist = distance.minkowski(tempdata[i],tempdata[j],1)\n",
    "                if (new_dist < min_dist):\n",
    "                    min_dist = new_dist\n",
    "                    min_vec = j\n",
    "    elif (d == 1): # Chebyshev\n",
    "        for j in range(tempdata.shape[0]):\n",
    "            if (templabel[i] != templabel[j]):\n",
    "                new_dist = distance.chebyshev(tempdata[i],tempdata[j])\n",
    "                if (new_dist < min_dist):\n",
    "                    min_dist = new_dist\n",
    "                    min_vec = j\n",
    "    elif (d == 2): # Correlation\n",
    "        for j in range(tempdata.shape[0]):\n",
    "            if (templabel[i] != templabel[j]):\n",
    "                new_dist = distance.correlation(tempdata[i],tempdata[j])\n",
    "                if (new_dist < min_dist):\n",
    "                    min_dist = new_dist\n",
    "                    min_vec = j\n",
    "    elif (d == 3): # Cosine\n",
    "        for j in range(tempdata.shape[0]):\n",
    "            if (templabel[i] != templabel[j]):\n",
    "                new_dist = distance.cosine(tempdata[i],tempdata[j])\n",
    "                if (new_dist < min_dist):\n",
    "                    min_dist = new_dist\n",
    "                    min_vec = j\n",
    "    elif (d == 4): # Euclidean\n",
    "        for j in range(tempdata.shape[0]):\n",
    "            if (templabel[i] != templabel[j]):\n",
    "#                new_dist = distance.euclidean(tempdata[i],tempdata[j]) # fast\n",
    "                new_dist = distance.minkowski(tempdata[i],tempdata[j],2)\n",
    "                if (new_dist < min_dist):\n",
    "                    min_dist = new_dist\n",
    "                    min_vec = j\n",
    "#    elif (d == 5): # Hamming\n",
    "#        for j in range(tempdata.shape[0]):\n",
    "#            if (templabel[i] != templabel[j]):\n",
    "#                new_dist = distance.hamming(tempdata[i],tempdata[j])\n",
    "#                if (new_dist < min_dist):\n",
    "#                    min_dist = new_dist\n",
    "#                    min_vec = j\n",
    "#    elif (d == 5): # Mahalanobis\n",
    "#        for j in range(tempdata.shape[0]):\n",
    "#            if (templabel[i] != templabel[j]):\n",
    "#                new_dist = distance.mahalanobis(tempdata[i],tempdata[j])\n",
    "#                if (new_dist < min_dist):\n",
    "#                    min_dist = new_dist\n",
    "#                    min_vec = j\n",
    "    elif (d == 5): # Minkowski p=3\n",
    "        for j in range(tempdata.shape[0]):\n",
    "            if (templabel[i] != templabel[j]):\n",
    "                new_dist = distance.minkowski(tempdata[i],tempdata[j],3)\n",
    "                if (new_dist < min_dist):\n",
    "                    min_dist = new_dist\n",
    "                    min_vec = j\n",
    "                    \n",
    "    return min_vec\n",
    "            \n",
    "# -------------------------------------------------------------------------------------\n",
    "# PARAMETERS\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "start_set = 0\n",
    "max_level = 4\n",
    "max_baseline = 13\n",
    "max_technique = max_level+max_baseline+1\n",
    "max_k = 5\n",
    "max_distance = 1\n",
    "reduction_load = 0\n",
    "reduction_save = 0\n",
    "encoder = 1 # label = 1, onehot = 2\n",
    "pca = 1\n",
    "pca_components = 0.99\n",
    "normalization = 1\n",
    "cross_validation = 1\n",
    "cross_validation_fold = 5\n",
    "parallel = 1\n",
    "model = 'knn' # knn, svm\n",
    "training = 1\n",
    "train_ratio = 0.3\n",
    "train_ratio_100k = 0.1\n",
    "train_ratio_500k = 0.01\n",
    "performance_save = 1\n",
    "figure_save = 1\n",
    "label_title = ('Accuracy','Precision','Recall','F1-Score','AUC (One-vs-Rest)','AUC (One-vs-One)','Reduction Rate','Class Balance')\n",
    "# Subscript = _, Superscript = ^, use {} for multiple letters\n",
    "label_traintype = ('ORG','CNN','ENN','RENN','All KNN','TL','OSS','NCL','NM$_1$','NM$_2$','NM$_3$','IHT','CC','RUS','CCNN$_1$','CCNN$_2$','CCNN$_3$','CCNN$_4$')\n",
    "\n",
    "# Reset performance files(Cross Validation)\n",
    "if (performance_save == 1):\n",
    "\n",
    "    files = glob.glob('*.txt')\n",
    "    for f in files:\n",
    "        os.remove(f)    \n",
    "    files = glob.glob('*.pdf')\n",
    "    for f in files:\n",
    "        os.remove(f)    \n",
    "    \n",
    "#    try: os.remove(\"class_balance.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"class_balance_percentage.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"reduction.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_fit_time.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_score_time.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_train_accuracy.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_train_precision.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_train_recall.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_train_f1.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_train_aucovr.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_train_aucovo.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_test_accuracy.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_test_precision.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_test_recall.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_test_f1.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_test_aucovr.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"cross_test_aucovo.txt\")\n",
    "#    except OSError: pass\n",
    "\n",
    "#    Without Cross Validation\n",
    "#    try: os.remove(\"perf_accuracy.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"perf_precision.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"perf_recall.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"perf_f1.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"perf_kappa*.txt\")\n",
    "#    try: os.remove(\"perf_roc.txt\")\n",
    "#    except OSError: pass\n",
    "\n",
    "#    try: os.remove(\"reduction_size.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"time_training.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"time_testing.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"time_reduction.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"mem_training_current.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"mem_testing_current.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"mem_training_peak.txt\")\n",
    "#    except OSError: pass\n",
    "#    try: os.remove(\"mem_testing_peak.txt\")\n",
    "#    except OSError: pass\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# LOADING DATA SETS\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "# Define the location of the dataset\n",
    "# https://archive.ics.uci.edu/ml/datasets.php\n",
    "# http://www.timeseriesclassification.com/dataset.php\n",
    "files = []\n",
    "file_header = []\n",
    "file_separator = []\n",
    "file_label = []\n",
    "file_big = []\n",
    "\n",
    "# # Small datasets\n",
    "# https://archive.ics.uci.edu/ml/datasets.php?format=&task=cla&att=&area=&numAtt=&numIns=&type=mvar&sort=nameUp&view=table\n",
    "\n",
    "# SYNTHETIC DATA SETS\n",
    "#files.append(\"https://piyabute.com/data/research/syntactic-square.csv\"); file_header.append(None); file_separator.append(\"\\t\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "#files.append(\"https://piyabute.com/data/research/syntactic-wave.csv\"); file_header.append(None); file_separator.append(\"\\t\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "# REAL-WORLD\n",
    "files.append(\"https://piyabute.com/data/research/banknote_authentication.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "files.append(\"https://piyabute.com/data/research/car.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "files.append(\"https://piyabute.com/data/research/crowdsourced_mapping.custom.csv\"); file_header.append(1); file_separator.append(\",\"); file_label.append(0); file_big.append(0); # 6A4C\n",
    "files.append(\"https://piyabute.com/data/research/letter-recognition.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(0); file_big.append(0); # 8A5C\n",
    "files.append(\"https://piyabute.com/data/research/optdigits.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 64A10C\n",
    "files.append(\"https://piyabute.com/data/research/pendigits.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 16A2C\n",
    "files.append(\"https://piyabute.com/data/research/statlog_landsat.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 36A6C\n",
    "files.append(\"https://piyabute.com/data/research/tic-tac-toe.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "files.append(\"https://piyabute.com/data/research/TUANDROMD.csv\"); file_header.append(0); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 36A6C\n",
    "files.append(\"https://piyabute.com/data/research/waveform-+noise.v2.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "\n",
    "# files.append(\"https://piyabute.com/data/research/australian.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "\n",
    "# Not the best one\n",
    "#files.append(\"https://piyabute.com/data/research/breast-cancer-wisconsin.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "# Slow training\n",
    "##files.append(\"https://piyabute.com/data/research/connect-4.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(1); # 6A4C\n",
    "## CCNN1 has only less instances of all classes than cross-validation, POOR\n",
    "#files.append(\"https://piyabute.com/data/research/glass.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "## CCNN1 has only less instances of class 0 than cross-validation\n",
    "#files.append(\"https://piyabute.com/data/research/iris.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "## Class 2 is too small (2 samples)\n",
    "#files.append(\"https://piyabute.com/data/research/nursery.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "# Poor f1\n",
    "#files.append(\"https://piyabute.com/data/research/page-blocks.data.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "# Poor f1\n",
    "#files.append(\"https://piyabute.com/data/research/spambase.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "# Not the best one\n",
    "#files.append(\"https://piyabute.com/data/research/statlog_image_segment.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "#files.append(\"https://piyabute.com/data/research/statlog_shuttle.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "##files.append(\"https://piyabute.com/data/research/waveform.v1.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "##files.append(\"https://piyabute.com/data/research/waveform-+noise.v1.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "#files.append(\"https://piyabute.com/data/research/waveform.v2.data.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "\n",
    "# # 100-1,000\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 4A3C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 10A2C\n",
    "##files.append(\"https://piyabute.com/data/research/breast-cancer.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 64A10C\n",
    "\n",
    "# file_header.append = line number of the attribute names (0 = first, None = none)\n",
    "# file_separator.append = separator\n",
    "# file_label.append = column number of the label (0 = first, -1 = last)\n",
    "\n",
    "# # 1,001-5,000\n",
    "#1\n",
    "#files.append(\"https://piyabute.com/data/research/iris.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00624/ckd-dataset-v2.csv\"); file_header.append(2); file_separator.append(\",\"); file_label.append(0); file_big.append(0); # 6A4C\n",
    "#1\n",
    "#files.append(\"https://piyabute.com/data/research/ckd-dataset-v2.csv\"); file_header.append(2); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "#2\n",
    "#files.append(\"https://piyabute.com/data/research/car.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "#files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 6A4C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00404/OBS-Network-DataSet_2_Aug27.arff\"); file_header.append(24); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 21A4C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 8A28C\n",
    "##files.append(\"https://piyabute.com/data/research/winequality-red.csv\"); file_header.append(0); file_separator.append(\";\"); file_label.append(-1); file_big.append(0); # 11A6C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"); file_header.append(0); file_separator.append(\";\"); file_label.append(-1); file_big.append(0); # 11A6C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"); file_header.append(0); file_separator.append(\";\"); file_label.append(-1); file_big.append(0); # 11A7C\n",
    "\n",
    "# 1,001-5,000 (high dimensions)\n",
    "#3\n",
    "#files.append(\"https://piyabute.com/data/research/TUANDROMD.csv\"); file_header.append(0); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 36A6C\n",
    "#files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 64A10C\n",
    "#4\n",
    "#files.append(\"https://piyabute.com/data/research/optdigits.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 64A10C\n",
    "#files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn\"); file_header.append(None); file_separator.append(\" \"); file_label.append(-1); file_big.append(0); # 36A6C\n",
    "#5\n",
    "#files.append(\"https://piyabute.com/data/research/sat.custom.csv\"); file_header.append(None); file_separator.append(\" \"); file_label.append(-1); file_big.append(0); # 36A6C\n",
    "#files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00622/TUANDROMD.csv\"); file_header.append(0); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 36A6C\n",
    "\n",
    "# 5,001-10,000\n",
    "#6\n",
    "#files.append(\"https://piyabute.com/data/research/pendigits.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 16A2C\n",
    "#files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits.tra\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 16A2C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00508/qsar_oral_toxicity.zip\"); file_header.append(0); file_separator.append(\";\"); file_label.append(-1); file_big.append(0); # 1024A2C\n",
    "    \n",
    "# 10,001-20,000\n",
    "#files.append(\"https://piyabute.com/data/research/aps_failure_training_set.csv\"); file_header.append(20); file_separator.append(\",\"); file_label.append(0); file_big.append(0); # 16A2C\n",
    "#7 Good, worse than CNN\n",
    "#files.append(\"https://piyabute.com/data/research/letter-recognition.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(0); file_big.append(0); # 8A5C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(0); file_big.append(0); # 8A5C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00468/online_shoppers_intention.csv\"); file_header.append(0); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 17A2C\n",
    "\n",
    "# 20,001-30,000\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 14A2C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"); file_header.append(1); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 24A2C\n",
    "\n",
    "# 30,001-40,000\n",
    "\n",
    "# 40,001-50,000\n",
    "# Poor\n",
    "#files.append(\"https://piyabute.com/data/research/nomao.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 64A10C\n",
    "##files.append(\"https://piyabute.com/data/research/default.custom.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 64A10C\n",
    "##files.append(\"https://piyabute.com/data/research/shuttle.custom.csv\"); file_header.append(None); file_separator.append(\" \"); file_label.append(-1); file_big.append(0); # 64A10C\n",
    "# Poor\n",
    "##files.append(\"https://piyabute.com/data/research/adult.csv\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 14A2C\n",
    "##files.append(\"https://piyabute.com/data/research/bank-additional-full.csv\"); file_header.append(0); file_separator.append(\";\"); file_label.append(0); file_big.append(0); # 8A5C\n",
    "\n",
    "\n",
    "# 50,001-100,000\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00542/log2.csv\"); file_header.append(0); file_separator.append(\",\"); file_label.append(4); file_big.append(0); # 11A4C\n",
    "##files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00325/Sensorless_drive_diagnosis.txt\"); file_header.append(None); file_separator.append(\" \"); file_label.append(-1); file_big.append(0); # 11A4C\n",
    "\n",
    "# 100,001-300,000\n",
    "#10\n",
    "#files.append(\"https://piyabute.com/data/nsl-kdd/KDDTrain+.txt\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 42A21C\n",
    "\n",
    "# 300,001-500,000\n",
    "#files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.data.gz\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 41A2C\n",
    "\n",
    "# >= 500,000\n",
    "#files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); # 54A7C\n",
    "\n",
    "# files.append(\"\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0); \n",
    "\n",
    "# Too small class members\n",
    "# files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0);\n",
    "# files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0);\n",
    "# files.append(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wpbc.data\"); file_header.append(None); file_separator.append(\",\"); file_label.append(-1); file_big.append(0);\n",
    "\n",
    "# Local data sets\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\elena-phoneme_5d_2c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-nursery_8d_5c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-poker_10d_10c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-winequality-red_12d_6c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-winequality-white_12d_7c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-adult_14d_2c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-pendigits_16d_10c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-bankmarketing_20d_2c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-defaultofcreditcardclients_23d_2c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-statloglandsat_36d_6c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-statlogshuttle_36d_7c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\elena-texture_40d_8c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-censusincome_41d_2c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-covertype_54d_7c.csv\")\n",
    "# files.append(\"D:\\\\Documents\\\\Google Drive\\\\Data Sets\\\\uci-optdigits_64d_10c.csv\")\n",
    "max_set = len(files)\n",
    "#max_set = 1\n",
    "\n",
    "# print(\"Task begins.\")\n",
    "\n",
    "#global_reduction = np.zeros((max_set,max_technique),dtype = np.float64)\n",
    "#global_fit_time = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_score_time = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_train_accuracy = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_train_precision = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_train_recall = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_train_f1 = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_train_aucovr = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_train_aucovo = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_test_accuracy = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_test_precision = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_test_recall = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_test_f1 = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_test_aucovr = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#global_test_aucovo = np.zeros((max_set,max_technique,max_k),dtype = np.float64)\n",
    "#max_test_accuracy = np.zeros((max_set,max_technique),dtype = np.float64)\n",
    "#max_test_precision = np.zeros((max_set,max_technique),dtype = np.float64)\n",
    "#max_test_recall = np.zeros((max_set,max_technique),dtype = np.float64)\n",
    "#max_test_f1 = np.zeros((max_set,max_technique),dtype = np.float64)\n",
    "#max_test_auc = np.zeros((max_set,max_technique),dtype = np.float64)\n",
    "#max_test_auc2 = np.zeros((max_set,max_technique),dtype = np.float64)\n",
    "\n",
    "for dataset in range(start_set,max_set):\n",
    "\n",
    "    # Define output storage\n",
    "    # perf_confusion_matrix=np.zeros(10,4,10,10)\n",
    "    # perf_confusion_matrix = np.zeros((max_set,max_technique,max_k),dtype=np.float64)\n",
    "    reduction = np.zeros((max_technique),dtype = np.intc)\n",
    "    perf_fit_time = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_score_time = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_train_accuracy = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_train_precision = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_train_recall = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_train_f1 = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_train_aucovr = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_train_aucovo = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "#    perf_train_accuracy_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_train_precision_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_train_recall_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_train_f1_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_train_aucovr_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_train_aucovo_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_train_kappa_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "    perf_test_accuracy = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_test_precision = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_test_recall = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_test_f1 = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_test_aucovr = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    perf_test_aucovo = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "#    perf_test_accuracy_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_test_precision_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_test_recall_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_test_f1_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_test_aucovr_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_test_aucovo_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "#    perf_test_kappa_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "    reduction_bar_value = np.zeros((max_technique),dtype = np.float64)\n",
    "    time_training = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    time_testing = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    time_reduction = np.zeros((max_technique),dtype = np.float64)\n",
    "    mem_training_current = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    mem_testing_current = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    mem_training_peak = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    mem_testing_peak = np.zeros((max_technique,max_k),dtype = np.float64)\n",
    "    k_array = np.zeros((max_k),dtype = np.intc)\n",
    "    d_array = np.zeros((max_set),dtype = np.intc)\n",
    "    l_array = np.zeros((max_technique),dtype = np.intc)\n",
    "    l_reduction = np.zeros((max_technique),dtype = np.float64)\n",
    "    \n",
    "    # Load data file to DataFrame\n",
    "    inputfile = files[dataset]\n",
    "    print(\"Dataset:\",dataset)\n",
    "    print(\"Data Source:\",inputfile)\n",
    "    if (inputfile[-2:] == \"gz\"):\n",
    "        df = pd.read_csv(inputfile, header = file_header[dataset], sep = file_separator[dataset], compression=\"gzip\")\n",
    "    elif (inputfile[-3:] == \".zip\"):\n",
    "        df = pd.read_csv(inputfile, header = file_header[dataset], sep = file_separator[dataset], compression=\"zip\")\n",
    "    elif (inputfile[-4:] == \".xls\") or (inputfile[-4:] == \"xlsx\"):\n",
    "        df = pd.read_excel(inputfile, header = file_header[dataset])      \n",
    "    else:\n",
    "        df = pd.read_csv(inputfile, header = file_header[dataset], sep = file_separator[dataset])\n",
    "\n",
    "        \n",
    "    # -------------------------------------------------------------------------------------\n",
    "    # PANDAS DATA PRE-PROCESSING\n",
    "    # -------------------------------------------------------------------------------------\n",
    "\n",
    "    # Drop specific rows\n",
    "    if (inputfile == \"https://piyabute.com/data/research/TUANDROMD.csv\"): df.drop(df.index[2533], inplace=True)\n",
    "    if (inputfile == \"https://piyabute.com/data/research/yeast.data\"): df.drop(labels=None, axis=0, inplace=True)\n",
    "   \n",
    "    # Stratified sampling\n",
    "    if (file_big[dataset] > 0): \n",
    "        # Generate column index\n",
    "        df.columns = df.columns.map(str)\n",
    "        df = df.groupby(df.columns[file_label[dataset]], group_keys=False).apply(lambda x: x.sample(file_big[dataset]))\n",
    "    \n",
    "    # Fill missing values (slow for big data)\n",
    "    #df = df.fillna(df.mean())\n",
    "    #df = df.fillna(df.median())\n",
    "    #df = df.fillna(df.mode())\n",
    "\n",
    "    # Convert dataframe to numpy\n",
    "    raw = df.to_numpy()\n",
    "\n",
    "    # -------------------------------------------------------------------------------------\n",
    "    # RAW DATA PRE-PROCESSING\n",
    "    # -------------------------------------------------------------------------------------\n",
    "\n",
    "    # Categorical to Numerical\n",
    "    if (encoder == 1):\n",
    "        labelencoder = LabelEncoder()\n",
    "        print(\"Preprocessing: Attribute =\",df.shape[1],\"[\",end=\"\")\n",
    "        dflist = df.dtypes.tolist()\n",
    "        for i in range(0,len(dflist)):\n",
    "            if (dflist[i]==\"object\"):\n",
    "                print(i,\"E \",end=\"\",sep=\"\")\n",
    "                raw[:,i] = labelencoder.fit_transform(raw[:,i])\n",
    "            elif (i==(len(dflist)-1) and file_label[dataset]==-1):\n",
    "                print(i,\"E \",end=\"\",sep=\"\")\n",
    "                raw[:,i] = labelencoder.fit_transform(raw[:,i])\n",
    "            elif (i==file_label[dataset]):\n",
    "                print(i,\"E \",end=\"\",sep=\"\")\n",
    "                raw[:,i] = labelencoder.fit_transform(raw[:,i])\n",
    "            else:\n",
    "                print(i,\" \",end=\"\",sep=\"\")\n",
    "        print(\"] (LabelEncoding)\")\n",
    "    elif (encoder == 2): # Incomplete!\n",
    "        print(\"Preprocessing: Attribute =\",df.shape[1],\"(\",end=\"\")\n",
    "        dflist = df.dtypes.tolist()\n",
    "        for i in range(0,len(dflist)-1):\n",
    "            if (dflist[i]==\"object\"):\n",
    "                print(i,\"E \",end=\"\",sep=\"\")\n",
    "                # creating instance of one-hot-encoder\n",
    "                enc = OneHotEncoder(categories='all', drop=None, sparse=True, handle_unknown='ignore')\n",
    "                encode_temp = enc.fit_transform(raw[:,i].reshape(-1,1)).toarray()\n",
    "                raw = np.concatenate((raw, encode_temp), axis=0, out=None)\n",
    "            else:\n",
    "                print(i,\" \",end=\"\",sep=\"\")\n",
    "        labelencoder = LabelEncoder()\n",
    "        raw[:,len(dflist)-1] = labelencoder.fit_transform(raw[:,len(dflist)-1])\n",
    "        print(\") (OneHotEncoding)\")\n",
    "        \n",
    "    # Extract the label attribute\n",
    "    trainsetlabel = raw[:,file_label[dataset]]\n",
    "    trainsetlabel = trainsetlabel.astype(int)\n",
    "\n",
    "    # Remove the label attribute\n",
    "    trainsetdata = np.delete(raw,file_label[dataset],1)\n",
    "\n",
    "    # Calculate PCA\n",
    "    if (pca == 1):\n",
    "        # pca = PCA(n_components=pca_components,svd_solver=\"full\")\n",
    "        mypca = PCA(n_components=pca_components)\n",
    "        traindata = mypca.fit_transform(trainsetdata)\n",
    "        trainlabel = trainsetlabel\n",
    "    else:\n",
    "        traindata = trainsetdata\n",
    "        trainlabel = trainsetlabel\n",
    "    \n",
    "    # Normalize normal attributes using MinMacScaler\n",
    "    if (normalization == 1):\n",
    "        scaler = MinMaxScaler(feature_range=(0.01, 0.99))\n",
    "        scaler.fit(traindata)\n",
    "        traindata = scaler.transform(traindata)\n",
    "        trainlabel = trainlabel - np.amin(trainlabel)\n",
    "      \n",
    "    # Construct the training set and test set\n",
    "    if (cross_validation == 1):\n",
    "        testdata = []\n",
    "        testlabel = []\n",
    "        trainsize = traindata.shape[0]\n",
    "        traindimension = traindata.shape[1]\n",
    "        reduction[max_level] = trainsize\n",
    "    else:\n",
    "        if ((traindata.shape[0]*traindata.shape[1])<100000):\n",
    "            traindata, testdata, trainlabel, testlabel = train_test_split(traindata, trainlabel, train_size=train_ratio, stratify=trainlabel, random_state=42)\n",
    "        elif ((traindata.shape[0]*traindata.shape[1])<500000):\n",
    "            traindata, testdata, trainlabel, testlabel = train_test_split(traindata, trainlabel, train_size=train_ratio_100k, stratify=trainlabel, random_state=42)\n",
    "        else:\n",
    "            traindata, testdata, trainlabel, testlabel = train_test_split(traindata, trainlabel, train_size=train_ratio_500k, stratify=trainlabel, random_state=42)\n",
    "        trainsize = traindata.shape[0]\n",
    "        traindimension = traindata.shape[1]\n",
    "        testsize = testdata.shape[0]\n",
    "        testdimension = testdata.shape[1]\n",
    "        reduction[max_level] = trainsize     \n",
    "\n",
    "    print(\"Preprocessing: Attribute =\",traindimension,\"(PCA)\" if pca==1 else \"(Non-PCA)\",\"(Norm)\" if normalization==1 else \"(Non-Norm)\")\n",
    "    print(\"Preprocessing: Sample    =\",trainsize)\n",
    "    print(\"Preprocessing: Class     =\", len(np.unique(trainlabel)), np.unique(trainlabel))\n",
    "    reduction_class = np.zeros((max_technique,len(np.unique(trainlabel))),dtype = np.float64)\n",
    "\n",
    "    # Print class balance\n",
    "    unique_train, counts_train = np.unique(trainlabel, return_counts=True)\n",
    "    print(\"Preprocessing: Train     =\",dict(zip(unique_train, counts_train)))\n",
    "    if (cross_validation == 0):\n",
    "        unique_test, counts_test = np.unique(testlabel, return_counts=True)\n",
    "        print(\"Preprocessing: Test      =\",dict(zip(unique_test, counts_test)))\n",
    "\n",
    "    # Plot original data\n",
    "#    if (figure_save == 1):\n",
    "#        if (traindimension == 2):\n",
    "#            scatter_x = traindata[:,0]\n",
    "#            scatter_y = traindata[:,1]\n",
    "#            scatter_x_min = min(scatter_x)\n",
    "#            scatter_x_max = max(scatter_x)\n",
    "#            scatter_y_min = min(scatter_y)\n",
    "#            scatter_y_max = max(scatter_y)\n",
    "#            group = trainlabel\n",
    "\n",
    "#            fig, ax = plt.subplots()\n",
    "#            for g in np.unique(group):\n",
    "#                ix = np.where(group == g)\n",
    "#                ax.scatter(scatter_x[ix], scatter_y[ix], label = g, s = 1, alpha=0.5)\n",
    "##            ax.legend(loc='upper left')\n",
    "#            plt.xlim([scatter_x_min,scatter_x_max])\n",
    "#            plt.ylim([scatter_y_min,scatter_y_max])\n",
    "#            plt.xlabel('X')\n",
    "#            plt.ylabel('Y')\n",
    "##            plt.savefig(os.path.basename(inputfile)+\"-org.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None)\n",
    "#            plt.savefig(\"instance-\"+str(dataset+1).zfill(2)+\"-org.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.02, metadata=None)\n",
    "#            plt.show()\n",
    "\n",
    "#        if (traindimension == 3):\n",
    "#            scatter_x = traindata[:,0]\n",
    "#            scatter_y = traindata[:,1]\n",
    "#            scatter_z = traindata[:,2]\n",
    "#            scatter_x_min = min(scatter_x)\n",
    "#            scatter_x_max = max(scatter_x)\n",
    "#            scatter_y_min = min(scatter_y)\n",
    "#            scatter_y_max = max(scatter_y)\n",
    "#            scatter_z_min = min(scatter_z)\n",
    "#            scatter_z_max = max(scatter_z)\n",
    "#            group = trainlabel\n",
    "\n",
    "#            fig = plt.figure()\n",
    "#            ax = fig.add_subplot(projection=\"3d\")\n",
    "#            for g in np.unique(group):\n",
    "#                ix = np.where(group == g)\n",
    "#                ax.scatter(scatter_x[ix], scatter_y[ix], scatter_z[ix], label = g, s = 1, alpha=0.5)\n",
    "##            ax.legend(loc='upper left')\n",
    "#            plt.xlim([scatter_x_min,scatter_x_max])\n",
    "#            plt.ylim([scatter_y_min,scatter_y_max])\n",
    "#            plt.zlim([scatter_z_min,scatter_z_max])\n",
    "#            plt.xlabel('X')\n",
    "#            plt.ylabel('Y')\n",
    "#            plt.zlabel('Z')\n",
    "##            ax.set_zlim([scatter_z_min,scatter_z_max])\n",
    "##            plt.savefig(os.path.basename(inputfile)+\"-org.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None)\n",
    "#            plt.savefig(\"instance-\"+str(dataset+1).zfill(2)+\"-org.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.02, metadata=None)\n",
    "#            plt.show()\n",
    "\n",
    "#    for d in range(0,max_distance):\n",
    "    for d in range(4,5):\n",
    "\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        # MY DATA REDUCTION\n",
    "        # -------------------------------------------------------------------------------------\n",
    "\n",
    "        print(\"Reduction begins...\")\n",
    "        tempset = raw\n",
    "        tempdata = traindata\n",
    "        templabel = trainlabel\n",
    "        scatter_x = []\n",
    "        scatter_y = []\n",
    "\n",
    "        for level in range(0,max_level):\n",
    "\n",
    "            time_start = time.perf_counter()\n",
    "\n",
    "            # Parallel or serialized reduction\n",
    "            if (parallel == 1):\n",
    "                if __name__ == \"__main__\":\n",
    "                    ProcessList = Parallel(n_jobs=num_cores)(delayed(find_minimum_distance)(d,i) for i in range(tempdata.shape[0]))\n",
    "            else:\n",
    "                ProcessList = [0]*tempdata.shape[0]\n",
    "                for i in range(0,tempdata.shape[0]):\n",
    "                    ProcessList[i] = find_minimum_distance(i)\n",
    "                    print(i,templabel[i],ProcessList[i],templabel[ProcessList[i]])\n",
    "            trainvectormin = np.unique(ProcessList)\n",
    "            traindataunique = tempdata[trainvectormin]\n",
    "            trainlabelunique = templabel[trainvectormin]\n",
    "\n",
    "            # Remove duplication\n",
    "            time_stop = time.perf_counter()\n",
    "            time_reduction[max_baseline+level+1] = time_stop - time_start\n",
    "\n",
    "            if level == 0:\n",
    "                traindataunique1 = traindataunique\n",
    "                trainlabelunique1 = trainlabelunique\n",
    "                tempsetbefore = tempdata.shape[0]\n",
    "                tempdata1 = np.delete(tempdata,trainvectormin,0)\n",
    "                templabel1 = np.delete(templabel,trainvectormin,0)\n",
    "\n",
    "#                # Maintain minimum values for n-fold cross-validation\n",
    "#                unique_templabel, counts_templabel = np.unique(templabel1, return_counts=True)\n",
    "#                mydict = dict(zip(unique_templabel,counts_templabel))\n",
    "#                for i in mydict: \n",
    "#                    mydict[i]=np.maximum(mydict[i],cross_validation_fold*max_k*2)\n",
    "#                mymodel = SMOTE(n_jobs=-1,sampling_strategy=mydict)\n",
    "#                tempdata, templabel = mymodel.fit_resample(tempdata1, templabel1)\n",
    "#                tempsetafter = tempdata.shape[0]\n",
    "\n",
    "                tempdata = tempdata1\n",
    "                templabel = templabel1\n",
    "                tempsetafter = tempdata1.shape[0]\n",
    "            elif level == 1:\n",
    "                traindataunique2 = traindataunique\n",
    "                trainlabelunique2 = trainlabelunique\n",
    "                tempsetbefore = tempdata.shape[0]\n",
    "                tempdata2 = np.delete(tempdata,trainvectormin,0)\n",
    "                templabel2 = np.delete(templabel,trainvectormin,0)\n",
    "\n",
    "#                # Maintain minimum values for n-fold cross-validation\n",
    "#                unique_templabel, counts_templabel = np.unique(templabel2, return_counts=True)\n",
    "#                mydict = dict(zip(unique_templabel,counts_templabel))\n",
    "#                for i in mydict: \n",
    "#                    mydict[i]=np.maximum(mydict[i],cross_validation_fold*max_k*2)\n",
    "#                mymodel = SMOTE(n_jobs=-1,sampling_strategy=mydict)\n",
    "#                tempdata, templabel = mymodel.fit_resample(tempdata2, templabel2)\n",
    "#                tempsetafter = tempdata.shape[0]\n",
    "\n",
    "                tempdata = tempdata2\n",
    "                templabel = templabel2\n",
    "                tempsetafter = tempdata2.shape[0]\n",
    "            elif level == 2:\n",
    "                traindataunique3 = traindataunique\n",
    "                trainlabelunique3 = trainlabelunique\n",
    "                tempsetbefore = tempdata.shape[0]\n",
    "                tempdata3 = np.delete(tempdata,trainvectormin,0)\n",
    "                templabel3 = np.delete(templabel,trainvectormin,0)\n",
    "\n",
    "#                # Maintain minimum values for n-fold cross-validation\n",
    "#                unique_templabel, counts_templabel = np.unique(templabel3, return_counts=True)\n",
    "#                mydict = dict(zip(unique_templabel,counts_templabel))\n",
    "#                for i in mydict: \n",
    "#                    mydict[i]=np.maximum(mydict[i],cross_validation_fold*max_k*2)\n",
    "#                mymodel = SMOTE(n_jobs=-1,sampling_strategy=mydict)\n",
    "#                tempdata, templabel = mymodel.fit_resample(tempdata3, templabel3)\n",
    "#                tempsetafter = tempdata.shape[0]\n",
    "\n",
    "                tempdata = tempdata3\n",
    "                templabel = templabel3\n",
    "                tempsetafter = tempdata3.shape[0]\n",
    "            elif level == 3:\n",
    "                traindataunique4 = traindataunique\n",
    "                trainlabelunique4 = trainlabelunique\n",
    "                tempsetbefore = tempdata.shape[0]\n",
    "                tempdata4 = np.delete(tempdata,trainvectormin,0)\n",
    "                templabel4 = np.delete(templabel,trainvectormin,0)\n",
    "\n",
    "#                # Maintain minimum values for n-fold cross-validation\n",
    "#                unique_templabel, counts_templabel = np.unique(templabel4, return_counts=True)\n",
    "#                mydict = dict(zip(unique_templabel,counts_templabel))\n",
    "#                for i in mydict: \n",
    "#                    mydict[i]=np.maximum(mydict[i],cross_validation_fold*max_k*2)\n",
    "#                mymodel = SMOTE(n_jobs=-1,sampling_strategy=mydict)\n",
    "#                tempdata, templabel = mymodel.fit_resample(tempdata4, templabel4)\n",
    "#                tempsetafter = tempdata.shape[0]\n",
    "\n",
    "                tempdata = tempdata4\n",
    "                templabel = templabel4\n",
    "                tempsetafter = tempdata4.shape[0]\n",
    "\n",
    "            print(\"Reduction: Level \",level+1,\" is constructed. / Time = \",\"{:0.2f}\".format(time_stop - time_start),\" seconds / Size = \",traindataunique.shape[0],\" / Original = \",tempsetbefore,\" / Remain = \", tempsetafter, sep = \"\")\n",
    "\n",
    "            # Save reduced data sets\n",
    "            if (reduction_save == 1):\n",
    "                if (pca == 1):\n",
    "                    outputfile = inputfile[:-4]+\"_pca_\"+str(level+1)+\".csv\"\n",
    "                else:\n",
    "                    outputfile = inputfile[:-4]+\"_\"+str(level+1)+\".csv\"\n",
    "                with open(outputfile, \"ab\") as file:\n",
    "                    if (level == 0):\n",
    "                        np.savetxt(file, np.c_[traindataunique1, np.array(trainlabelunique1)], delimiter=\",\", fmt=\"%1.4f\")            \n",
    "                    elif (level == 1):\n",
    "                        np.savetxt(file, np.c_[traindataunique2, np.array(trainlabelunique2)], delimiter=\",\", fmt=\"%1.4f\")            \n",
    "                    elif (level == 2):\n",
    "                        np.savetxt(file, np.c_[traindataunique3, np.array(trainlabelunique3)], delimiter=\",\", fmt=\"%1.4f\")            \n",
    "                    elif (level == 3):\n",
    "                        np.savetxt(file, np.c_[traindataunique4, np.array(trainlabelunique4)], delimiter=\",\", fmt=\"%1.4f\")            \n",
    "                    print(\"Saving level \"+str(level+1)+\" to \"+outputfile, sep=\" \")\n",
    "                       \n",
    "        # -------------------------------------------------------------------------------------\n",
    "        # Training Set Construction\n",
    "        # -------------------------------------------------------------------------------------\n",
    "\n",
    "        # https://imbalanced-learn.org/\n",
    "        print(\"Training:\")\n",
    "        for traintype in range(0,max_technique):\n",
    "            if traintype == 0:\n",
    "                xready = traindata\n",
    "                tready = trainlabel\n",
    "                temp, reduction_class_org = np.unique(tready, return_counts=True)\n",
    "            elif traintype < 14:\n",
    "                time_start = time.perf_counter()\n",
    "                if traintype == 1:\n",
    "                    mymodel = CondensedNearestNeighbour(n_jobs=-1,sampling_strategy='all')\n",
    "                elif traintype == 2:\n",
    "                    mymodel = EditedNearestNeighbours(n_jobs=-1,sampling_strategy='all',kind_sel='mode')\n",
    "                elif traintype == 3:\n",
    "                    mymodel = RepeatedEditedNearestNeighbours(n_jobs=-1,sampling_strategy='all',kind_sel='mode')\n",
    "                elif traintype == 4:\n",
    "                    mymodel = AllKNN(n_jobs=-1,sampling_strategy='all',kind_sel='mode')\n",
    "                elif traintype == 5:\n",
    "                    mymodel = TomekLinks(n_jobs=-1,sampling_strategy='all')\n",
    "                elif traintype == 6:\n",
    "                    mymodel = OneSidedSelection(n_jobs=-1,sampling_strategy='all')\n",
    "                elif traintype == 7:\n",
    "                    mymodel = NeighbourhoodCleaningRule(n_jobs=-1,sampling_strategy='all',kind_sel='mode')\n",
    "                elif traintype == 8:\n",
    "                    mymodel = NearMiss(n_jobs=-1,sampling_strategy='all',version=1)\n",
    "                elif traintype == 9:\n",
    "                    mymodel = NearMiss(n_jobs=-1,sampling_strategy='all',version=2)\n",
    "                elif traintype == 10:\n",
    "                    mymodel = NearMiss(n_jobs=-1,sampling_strategy='all',version=3)\n",
    "                elif traintype == 11:\n",
    "                    mymodel = InstanceHardnessThreshold(n_jobs=-1,sampling_strategy='all')\n",
    "                elif traintype == 12:\n",
    "                    mymodel = ClusterCentroids(n_jobs=-1,sampling_strategy='all',voting='auto')\n",
    "                elif traintype == 13:\n",
    "                    mymodel = RandomUnderSampler(sampling_strategy='all',replacement=True)\n",
    "                 \n",
    "                xready, tready = mymodel.fit_resample(traindata, trainlabel)\n",
    "                time_stop = time.perf_counter()\n",
    "                time_reduction[traintype] = time_stop - time_start\n",
    "            else: # SMOTE\n",
    "                if traintype == 14:\n",
    "                    xready = traindataunique1\n",
    "                    tready = trainlabelunique1\n",
    "                elif traintype == 15:\n",
    "                    xready = np.vstack((traindataunique1,traindataunique2))\n",
    "                    tready = np.hstack((trainlabelunique1,trainlabelunique2))\n",
    "                elif traintype == 16:\n",
    "                    xready = np.vstack((traindataunique1,traindataunique2,traindataunique3))\n",
    "                    tready = np.hstack((trainlabelunique1,trainlabelunique2,trainlabelunique3))\n",
    "                elif traintype == 17:\n",
    "                    xready = np.vstack((traindataunique1,traindataunique2,traindataunique3,traindataunique4))\n",
    "                    tready = np.hstack((trainlabelunique1,trainlabelunique2,trainlabelunique3,trainlabelunique4))\n",
    "\n",
    "            unique_tready, counts_tready = np.unique(tready, return_counts=True)\n",
    "#            print(\"Training: Type \",traintype,\" \",label_traintype[traintype],\"; set=\",dataset,\"; sample=\", len(tready),\" ({:0.2f}\".format(len(tready)/len(trainlabel)*100), \"%) \", dict(zip(unique_tready, counts_tready)), sep = \"\");\n",
    "\n",
    "            # OverSampling CCNN\n",
    "            if traintype >=14:\n",
    "#            if traintype > 0:\n",
    "                # Maintain minimum values for n-fold cross-validation\n",
    "                unique_tready, counts_tready = np.unique(tready, return_counts=True)\n",
    "                mydict = dict(zip(unique_tready,counts_tready))\n",
    "                print(\"Training: (Pre) Type \",traintype,\" \",label_traintype[traintype],\"; set=\",dataset,\"; sample=\", len(tready),\" ({:0.2f}\".format(len(tready)/len(trainlabel)*100), \"%) \", dict(zip(unique_tready, counts_tready)), sep = \"\");\n",
    "                for i in mydict: \n",
    "                    mydict[i]=np.maximum(mydict[i],cross_validation_fold*max_k*2)\n",
    "\n",
    "#                mymodel_smote = SMOTE(n_jobs=-1,sampling_strategy=mydict)\n",
    "                mymodel_ros = RandomOverSampler(sampling_strategy=mydict)\n",
    "                xready, tready = mymodel_ros.fit_resample(xready, tready)\n",
    "                unique_tready, counts_tready = np.unique(tready, return_counts=True)\n",
    "            print(\"Training: (Post) Type \",traintype,\" \",label_traintype[traintype],\"; set=\",dataset,\"; sample=\", len(tready),\" ({:0.2f}\".format(len(tready)/len(trainlabel)*100), \"%) \", dict(zip(unique_tready, counts_tready)), sep = \"\");\n",
    "\n",
    "            if (len(np.unique(tready))<len(np.unique(trainlabel))):\n",
    "                print(\"Training: Cannot maintain all class labels!\")\n",
    "#                continue\n",
    "\n",
    "            reduction[traintype] = len(tready)\n",
    "\n",
    "            # Fixing empty class\n",
    "            j = 0;\n",
    "            for i in unique_tready:\n",
    "                reduction_class[traintype][i] = counts_tready[j]\n",
    "                j += 1\n",
    "\n",
    "            # Plot training sets\n",
    "            if (figure_save == 1):\n",
    "                colors = ['g','b','r','m'];\n",
    "                if (traindimension == 2):\n",
    "                    scatter_x = xready[:,0]\n",
    "                    scatter_y = xready[:,1]\n",
    "#                    scatter_x_min = min(scatter_x)\n",
    "#                    scatter_x_max = max(max(scatter_x),1)\n",
    "#                    scatter_y_min = min(scatter_y)\n",
    "#                    scatter_y_max = max(max(scatter_y),1)\n",
    "                    scatter_x_min = 0\n",
    "                    scatter_x_max = 1\n",
    "                    scatter_y_min = 0\n",
    "                    scatter_y_max = 1\n",
    "                    group = tready\n",
    "                    plt.scatter(scatter_x, scatter_y, c=tready, cmap=matplotlib.colors.ListedColormap(colors), s = 1, alpha=0.5);\n",
    "                    plt.xlim([scatter_x_min,scatter_x_max])\n",
    "                    plt.ylim([scatter_y_min,scatter_y_max])\n",
    "                    plt.xlabel('X')\n",
    "                    plt.ylabel('Y')\n",
    "                    plt.savefig(\"instance-\"+str(dataset+1).zfill(2)+\"-\"+str(traintype+1).zfill(2)+\".pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.02, metadata=None)\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "\n",
    "                if (traindimension == 3):\n",
    "                    scatter_x = xready[:,0]\n",
    "                    scatter_y = xready[:,1]\n",
    "                    scatter_z = xready[:,2]\n",
    "#                    scatter_x_min = min(scatter_x)\n",
    "#                    scatter_x_max = max(max(scatter_x),1)\n",
    "#                    scatter_y_min = min(scatter_y)\n",
    "#                    scatter_y_max = max(max(scatter_y),1)\n",
    "#                    scatter_z_min = min(scatter_z)\n",
    "#                    scatter_z_max = max(max(scatter_z),1)\n",
    "                    scatter_x_min = 0\n",
    "                    scatter_x_max = 1\n",
    "                    scatter_y_min = 0\n",
    "                    scatter_y_max = 1\n",
    "                    scatter_z_min = 0\n",
    "                    scatter_z_max = 1\n",
    "                    group = tready\n",
    "                    plt.scatter(scatter_x, scatter_y, scatter_z, c=tready, cmap=matplotlib.colors.ListedColormap(colors), s = 1, alpha=0.5);\n",
    "                    plt.xlim([scatter_x_min,scatter_x_max])\n",
    "                    plt.ylim([scatter_y_min,scatter_y_max])\n",
    "                    plt.zlim([scatter_z_min,scatter_z_max])\n",
    "                    plt.xlabel('X')\n",
    "                    plt.ylabel('Y')\n",
    "                    plt.zlabel('Z')\n",
    "                    plt.savefig(\"instance-\"+str(dataset+1).zfill(2)+\"-\"+str(traintype+1).zfill(2)+\".pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.02, metadata=None)\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "\n",
    "            # -------------------------------------------------------------------------------------\n",
    "            # LAZY LEARNING ALGORITHMS\n",
    "            # -------------------------------------------------------------------------------------\n",
    "\n",
    "            # k-Nearest Neighbors\n",
    "            # https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    "            # https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "            # Local Regression\n",
    "            # Lazy naive Bayes\n",
    "            # SVM RBF\n",
    "\n",
    "            # Execute loop only once for non-knn\n",
    "            if (model != 'knn'): max_k = 0\n",
    "\n",
    "            for k in range(0,max_k,1):\n",
    "\n",
    "                # Training Cross validation\n",
    "                # https://towardsdatascience.com/cross-validation-using-knn-6babb6e619c8\n",
    "                # https://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a\n",
    "                # https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "                # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
    "                # https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "                tracemalloc.start()\n",
    "                time_start = time.perf_counter()\n",
    "                if (model == 'knn'):\n",
    "                    clf = KNeighborsClassifier(n_neighbors=(2*k)+1,n_jobs=-1)\n",
    "                elif (model == 'svm'):\n",
    "                    clf = svm.SVC(kernel='linear', C=1, random_state=0,probability=True)\n",
    "\n",
    "                if (min(counts_tready)>cross_validation_fold):\n",
    "                    cross_validation_fold_final = cross_validation_fold\n",
    "                elif (min(counts_tready)>2):\n",
    "                    cross_validation_fold_final = min(counts_tready)\n",
    "                else:\n",
    "                    cross_validation_fold_final = 2\n",
    "\n",
    "                # Early break if class members are less than k\n",
    "                # if (min(counts_tready)/cross_validation_fold_final<k+1): break\n",
    "\n",
    "                # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "                # https://sciksit-learn.org/stable/modules/model_evaluation.html\n",
    "                # scores = cross_val_score(clf, xready, tready, cv=cross_validation_fold)\n",
    "                scoring = {\"accuracy\":\"accuracy\",\n",
    "                           \"precision\":\"precision_weighted\",\n",
    "                           \"recall\":\"recall_weighted\",\n",
    "                           \"f1\":\"f1_weighted\",\n",
    "                           \"aucovr\":\"roc_auc_ovr_weighted\",\n",
    "                           \"aucovo\":\"roc_auc_ovo_weighted\"}\n",
    "                skf = StratifiedKFold(n_splits=cross_validation_fold_final, random_state=0, shuffle=True)\n",
    "#                skf = KFold(n_splits=cross_validation_fold_final, random_state=0, shuffle=True)\n",
    "                scores = cross_validate(clf, xready, tready, scoring=scoring, cv=skf, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "                time_stop = time.perf_counter()\n",
    "                current, peak = tracemalloc.get_traced_memory()\n",
    "                tracemalloc.stop()\n",
    "                mem_training_current[traintype,k] = current\n",
    "                mem_training_peak[traintype,k] = peak\n",
    "                time_training[traintype,k] = time_stop - time_start\n",
    "\n",
    "#                global_fit_time[dataset,traintype,k] = \n",
    "                perf_fit_time[traintype,k] = statistics.mean(scores[\"fit_time\"])\n",
    "#                global_score_time[dataset,traintype,k] = \n",
    "                perf_score_time[traintype,k] = statistics.mean(scores[\"score_time\"])\n",
    "#                global_train_accuracy[dataset,traintype,k] = \n",
    "                perf_train_accuracy[traintype,k] = statistics.mean(scores[\"train_accuracy\"])\n",
    "#                global_train_precision[dataset,traintype,k] = \n",
    "                perf_train_precision[traintype,k] = statistics.mean(scores[\"train_precision\"])\n",
    "#                global_train_recall[dataset,traintype,k] = \n",
    "                perf_train_recall[traintype,k] = statistics.mean(scores[\"train_recall\"])\n",
    "#                global_train_f1[dataset,traintype,k] = \n",
    "                perf_train_f1[traintype,k] = statistics.mean(scores[\"train_f1\"])\n",
    "#                global_train_aucovr[dataset,traintype,k] = \n",
    "                perf_train_aucovr[traintype,k] = statistics.mean(scores[\"train_aucovr\"])\n",
    "#                global_train_aucovo[dataset,traintype,k] = \n",
    "                perf_train_aucovo[traintype,k] = statistics.mean(scores[\"train_aucovo\"])\n",
    "#                global_train_kappa[dataset,traintype,k] = \n",
    "#                perf_train_kappa[traintype,k] = statistics.mean(scores[\"train_kappa\"])\n",
    "#                global_test_accuracy[dataset,traintype,k] = \n",
    "                perf_test_accuracy[traintype,k] = statistics.mean(scores[\"test_accuracy\"])\n",
    "#                global_test_precision[dataset,traintype,k] = \n",
    "                perf_test_precision[traintype,k] = statistics.mean(scores[\"test_precision\"])\n",
    "#                global_test_recall[dataset,traintype,k] = \n",
    "                perf_test_recall[traintype,k] = statistics.mean(scores[\"test_recall\"])\n",
    "#                global_test_f1[dataset,traintype,k] = \n",
    "                perf_test_f1[traintype,k] = statistics.mean(scores[\"test_f1\"])\n",
    "#                global_test_aucovr[dataset,traintype,k] = \n",
    "                perf_test_aucovr[traintype,k] = statistics.mean(scores[\"test_aucovr\"])\n",
    "#                global_test_aucovo[dataset,traintype,k] = \n",
    "                perf_test_aucovo[traintype,k] = statistics.mean(scores[\"test_aucovo\"])\n",
    "\n",
    "                if (model == 'knn2'):\n",
    "                    print(\"Training: Type \",label_traintype[traintype],\n",
    "#                          \"; MEM=\",\"{:5.0f}\".format(mem_training_current[k]/1000000),\"{:5.0f}\".format(mem_training_peak[k]/1000000),                     \n",
    "                          \"; cv=\",cross_validation_fold_final,\n",
    "                          \"; d=\",d,\n",
    "                          \"; k=\",(2*k)+1,\n",
    "                          \"; Train=\",reduction[traintype],\n",
    "                          \"; Acc=\",\"{:0.2f}\".format(perf_test_accuracy[traintype,k]),\n",
    "                          \"; Pre=\",\"{:0.2f}\".format(perf_test_precision[traintype,k]),\n",
    "                          \"; Recall=\",\"{:0.2f}\".format(perf_test_recall[traintype,k]),\n",
    "                          \"; F1=\",\"{:0.2f}\".format(perf_test_f1[traintype,k]),\n",
    "                          \"; AUC OVR=\",\"{:0.2f}\".format(perf_test_aucovr[traintype,k]),\n",
    "                          \"; AUC OVO=\",\"{:0.2f}\".format(perf_test_aucovo[traintype,k]),sep = \"\")\n",
    "                elif (model == 'svm2'):\n",
    "                    print(\"Training: Type \",label_traintype[traintype],\n",
    "#                                   \"; MEM=\",\"{:5.0f}\".format(mem_training_current[k]/1000000),\"{:5.0f}\".format(mem_training_peak[k]/1000000),                     \n",
    "                          \"; cv=\",cross_validation_fold_final,\n",
    "                          \"; d=\",d,\n",
    "                          \"; Train=\",reduction[traintype],\n",
    "                          \"; Acc=\",\"{:0.2f}\".format(sum(perf_test_accuracy[traintype])/len(perf_test_accuracy[traintype])),\n",
    "                          \"; Pre=\",\"{:0.2f}\".format(sum(perf_test_precision[traintype]/len(perf_test_precision[traintype]))),\n",
    "                          \"; Recall=\",\"{:0.2f}\".format(sum(perf_test_recall[traintype]/len(perf_test_recall[traintype]))),\n",
    "                          \"; F1=\",\"{:0.2f}\".format(sum(perf_test_f1[traintype]/len(perf_test_f1[traintype]))),\n",
    "                          \"; AUC OVR=\",\"{:0.2f}\".format(sum(perf_test_aucovr[traintype]/len(perf_test_aucovr[traintype]))),\n",
    "                          \"; AUC OVO=\",\"{:0.2f}\".format(sum(perf_test_aucovo[traintype]/len(perf_test_aucovo[traintype]))), sep = \"\")\n",
    "\n",
    "            # Save every train type\n",
    "            if (performance_save == 1):\n",
    "                with open(\"cross_fit_time.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_fit_time[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.8f\")\n",
    "                with open(\"cross_score_time.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_score_time[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.8f\")\n",
    "                with open(\"cross_train_accuracy.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_train_accuracy[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")\n",
    "                with open(\"cross_train_precision.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_train_precision[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_train_recall.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_train_recall[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_train_f1.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_train_f1[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_train_aucovr.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_train_aucovr[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_train_aucovo.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_train_aucovo[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_test_accuracy.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_test_accuracy[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")\n",
    "                with open(\"cross_test_precision.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_test_precision[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_test_recall.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_test_recall[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_test_f1.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_test_f1[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_test_aucovr.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_test_aucovr[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"cross_test_aucovo.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, perf_test_aucovo[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"time_training.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, time_training[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "                with open(\"mem_training_current.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, mem_training_current[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%0.0f\")        \n",
    "                with open(\"mem_training_peak.txt\", \"ab\") as file:\n",
    "                    np.savetxt(file, mem_training_peak[traintype].reshape(1,max_k), delimiter=\"\\t\", fmt=\"%0.0f\")        \n",
    "\n",
    "            # Print average scores\n",
    "            if (model == 'knn'):\n",
    "                print(\"Training: Type \",label_traintype[traintype],\n",
    "#                      \"; MEM=\",\"{:5.0f}\".format(mem_training_current[k]/1000000),\"{:5.0f}\".format(mem_training_peak[k]/1000000),                     \n",
    "                      \"; cv=\",cross_validation_fold_final,\n",
    "                      \"; d=\",d,\n",
    "                      \"; k=[1-\",(2*k)+1,\"]\",\n",
    "                      \"; Train=\",reduction[traintype],\n",
    "                      \"; Acc=\",\"{:0.2f}\".format(np.mean(perf_test_accuracy[traintype],axis=0)),\n",
    "                      \"; Pre=\",\"{:0.2f}\".format(np.mean(perf_test_precision[traintype],axis=0)),\n",
    "                      \"; Recall=\",\"{:0.2f}\".format(np.mean(perf_test_recall[traintype],axis=0)),\n",
    "                      \"; F1=\",\"{:0.2f}\".format(np.mean(perf_test_f1[traintype],axis=0)),\n",
    "                      \"; AUC OVR=\",\"{:0.2f}\".format(np.mean(perf_test_aucovr[traintype],axis=0)),\n",
    "                      \"; AUC OVO=\",\"{:0.2f}\".format(np.mean(perf_test_aucovo[traintype],axis=0)),sep = \"\")\n",
    "            elif (model == 'svm'):\n",
    "                print(\"Training: Type \",label_traintype[traintype],\n",
    "#                      \"; MEM=\",\"{:5.0f}\".format(mem_training_current[k]/1000000),\"{:5.0f}\".format(mem_training_peak[k]/1000000),                     \n",
    "                      \"; cv=\",cross_validation_fold_final,\n",
    "                      \"; d=\",d,\n",
    "                      \"; Train=\",reduction[traintype],\n",
    "                      \"; Acc=\",\"{:0.2f}\".format(np.mean(perf_test_accuracy[traintype],axis=0)),\n",
    "                      \"; Pre=\",\"{:0.2f}\".format(np.mean(perf_test_precision[traintype],axis=0)),\n",
    "                      \"; Recall=\",\"{:0.2f}\".format(np.mean(perf_test_recall[traintype],axis=0)),\n",
    "                      \"; F1=\",\"{:0.2f}\".format(np.mean(perf_test_f1[traintype],axis=0)),\n",
    "                      \"; AUC OVR=\",\"{:0.2f}\".format(np.mean(perf_test_aucovr[traintype],axis=0)),\n",
    "                      \"; AUC OVO=\",\"{:0.2f}\".format(np.mean(perf_test_aucovo[traintype],axis=0)),sep = \"\")\n",
    "            print()\n",
    "\n",
    "        # Save every data set\n",
    "        if (performance_save == 1):\n",
    "            with open(\"class_balance.txt\", \"ab\") as file:\n",
    "                np.savetxt(file, counts_train.reshape(1,counts_train.shape[0]), delimiter=\"\\t\", fmt=\"%0.0f\")\n",
    "            with open(\"class_balance_percentage.txt\", \"ab\") as file:\n",
    "                np.savetxt(file, (counts_train/traindata.shape[0]).reshape(1,counts_train.shape[0]), delimiter=\"\\t\", fmt=\"%0.4f\")\n",
    "            with open(\"reduction_size.txt\", \"ab\") as file:\n",
    "                np.savetxt(file, reduction.reshape(1,reduction.shape[0]), delimiter=\"\\t\", fmt=\"%0.0f\")\n",
    "            with open(\"reduction_class.txt\", \"ab\") as file:\n",
    "#                np.savetxt(file, reduction_class.reshape(len(reduction_class),reduction.shape[0]), delimiter=\"\\t\", fmt=\"%0.0f\")\n",
    "                np.savetxt(file, np.transpose(reduction_class), delimiter=\"\\t\", fmt=\"%0.0f\")\n",
    "            with open(\"time_reduction.txt\", \"ab\") as file:\n",
    "                np.savetxt(file, time_reduction.reshape(1,max_technique), delimiter=\"\\t\", fmt=\"%1.4f\")        \n",
    "\n",
    "        # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "        # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html\n",
    "        # https://matplotlib.org/stable/tutorials/introductory/customizing.html\n",
    "        # https://matplotlib.org/stable/api/matplotlib_configuration_api.html#matplotlib.rcParams\n",
    "\n",
    "        # Global pyplot parameters\n",
    "        plot_alpha = 0.9\n",
    "        plot_linewidth = 1\n",
    "        plot_width = 0.5\n",
    "        plot_barlsh = 0.2\n",
    "        plt.rcParams.update({'font.family':'cmr10'})\n",
    "        plt.rcParams['font.size'] = '12'\n",
    "        # https://matplotlib.org/3.5.1/tutorials/colors/colormaps.html\n",
    "        plt.rcParams[\"image.cmap\"] = 'tab20b'\n",
    "        plt.rcParams[\"scatter.edgecolors\"] = 'face'\n",
    "        \n",
    "        # Plot reduction rate\n",
    "        plt.figure(figsize=(14, 2.5))\n",
    "        plt.title('Reduction Rate of the Data Set '+str(dataset+1),fontsize=20,fontweight='bold')\n",
    "        plt.ylabel('Performance (Larger is better)')\n",
    "        plt.xticks(range(0,max_technique),label_traintype)\n",
    "        plt.xlabel('Technique')\n",
    "        plt.ylim([0,1.09])\n",
    "        plt.grid(color='grey', linewidth=1, axis='both', alpha=0.2)\n",
    "        for x in range(0,max_technique):\n",
    "            plt.bar(x,1-reduction[x]/reduction[0],label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "            plt.text(x-plot_barlsh,1-reduction[x]/reduction[0]+0.01,\"{:.2f}\".format(1-reduction[x]/reduction[0],2))\n",
    "        plt.savefig(\"reduction-\"+str(dataset+1).zfill(2)+\".pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.02, metadata=None)\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot class balances\n",
    "        plt.figure(figsize=(14, 2.5))\n",
    "        plt.title('Class-Level Reduction Rate of the Data Set '+str(dataset+1),fontsize=20,fontweight='bold')\n",
    "        plt.ylabel('Reduction Rate (Larger is better)')\n",
    "        plt.xticks(range(0,max_technique),label_traintype)\n",
    "        plt.xlabel('Technique')\n",
    "        plt.ylim([-0.09,1.09])\n",
    "        plt.grid(color='grey', linewidth=1, axis='both', alpha=0.2)\n",
    "        for c in range(0,len(reduction_class[0])): # classes\n",
    "#            plt.scatter(range(0,len(reduction_class)),np.transpose(reduction_class)[c]/np.transpose(reduction_class)[c][0],marker='.',label=label_traintype[0],linewidth=plot_linewidth,alpha=plot_alpha)#,label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "            plt.scatter(range(0,len(reduction_class)),1-np.transpose(reduction_class)[c]/np.transpose(reduction_class)[c][0],label=label_traintype[0],marker='.',linewidth=plot_linewidth,alpha=plot_alpha)#,label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "#            plt.bar(np.linspace(0+c/len(reduction_class[0]),len(reduction_class)-1+c/len(reduction_class[0]),len(reduction_class)),1-np.transpose(reduction_class)[c]/np.transpose(reduction_class)[c][0],label=label_traintype[c],width=1/(len(reduction_class[0]))-0.1,alpha=plot_alpha)\n",
    "#        plt.legend(range(0,len(reduction_class)))\n",
    "        plt.savefig(\"reduction-class-\"+str(dataset+1).zfill(2)+\".pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.02, metadata=None)\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot execution time\n",
    "        plt.figure(figsize=(14, 2.5))\n",
    "        plt.title('Execution Time of the Reduction Process of the Data Set '+str(dataset+1)+\" (seconds)\",fontsize=20,fontweight='bold')\n",
    "        plt.ylabel('Execution Time (Smaller is better)')\n",
    "        plt.xticks(range(0,max_technique),label_traintype)\n",
    "        plt.xlabel('Technique')\n",
    "        max_time_reduction = np.max(time_reduction)+time_reduction[13]+time_reduction[14]\n",
    "        if (max_time_reduction < 10):\n",
    "            plot_barlsh_exec = plot_barlsh\n",
    "        elif (max_time_reduction < 100):\n",
    "            plot_barlsh_exec = plot_barlsh + 0.7\n",
    "        elif (max_time_reduction < 1000):\n",
    "            plot_barlsh_exec = plot_barlsh + 0.13\n",
    "        elif (max_time_reduction < 10000):\n",
    "            plot_barlsh_exec = plot_barlsh + 0.19\n",
    "        else:\n",
    "            plot_barlsh_exec = plot_barlsh + 0.25\n",
    "        max_ylim = (np.max(time_reduction)+time_reduction[13]+time_reduction[14])*1.10\n",
    "        plt.ylim([0,max_ylim])\n",
    "        plt.grid(color='grey', linewidth=1, axis='both', alpha=0.2)\n",
    "        for x in range(0,max_technique):\n",
    "            if (x == max_techique-3): # CCNN1+CCNN2\n",
    "                plt.bar(x,time_reduction[x]+time_reduction[x-1],label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                plt.text(x-plot_barlsh_exec,time_reduction[x]+time_reduction[x-1],\"{:.2f}\".format(time_reduction[x]+time_reduction[x-1],2))\n",
    "            elif (x == max_techique-2): # CCNN1+CCNN2+CCNN3\n",
    "                plt.bar(x,time_reduction[x]+time_reduction[x-1]+time_reduction[x-2],label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                plt.text(x-plot_barlsh_exec,time_reduction[x]+time_reduction[x-1]+time_reduction[x-2],\"{:.2f}\".format(time_reduction[x]+time_reduction[x-1]+time_reduction[x-2],2))\n",
    "            elif (x == max_techique-1): # CCNN1+CCNN2+CCNN3+CCNN4\n",
    "                plt.bar(x,time_reduction[x]+time_reduction[x-1]+time_reduction[x-2]+time_reduction[x-3],label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                plt.text(x-plot_barlsh_exec,time_reduction[x]+time_reduction[x-1]+time_reduction[x-2]+time_reduction[x-3],\"{:.2f}\".format(time_reduction[x]+time_reduction[x-1]+time_reduction[x-2]+time_reduction[x-3],2))\n",
    "            else:\n",
    "                plt.bar(x,time_reduction[x],label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                plt.text(x-plot_barlsh_exec,time_reduction[x],\"{:.2f}\".format(time_reduction[x],2))\n",
    "        plt.savefig(\"time-reduction-\"+str(dataset+1).zfill(2)+\".pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.02, metadata=None)\n",
    "        plt.close()\n",
    "\n",
    "        # Plot performance comparisons among all techniques\n",
    "        for f in range(0,6): # 1 accuracy, 2 precision, 3 recall, 4 f1-score, 5 aucovr, 6 aucovo\n",
    "            plt.figure(figsize=(14, 2.5))\n",
    "            plt.title(label_title[f]+' of the Data Set '+str(dataset+1),fontsize=20,fontweight='bold')\n",
    "            plt.ylabel('Performance (Larger is better)')\n",
    "            plt.xticks(range(0,max_technique),label_traintype)\n",
    "            plt.xlabel('Technique')\n",
    "            plt.ylim([0,1.09])\n",
    "            plt.grid(color='grey', linewidth=1, axis='both', alpha=0.2)\n",
    "#            plt.axhline(y=0.1, xmin=0, xmax=max_technique)\n",
    "#            plt.axvline(x=5, ymin=0.1, ymax=0.9)\n",
    "\n",
    "            if (f == 0):\n",
    "                for x in range(0,max_technique): # x-0.33 for default font\n",
    "                    plt.bar(x,np.mean(perf_test_accuracy[x],axis=0),label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "#                    if (np.mean(perf_test_accuracy[x] > 0.95)):\n",
    "#                        plt.text(x-0.33,np.minimum(0.95,np.mean(perf_test_accuracy[x])-0.04),\"{:.2f}\".format(np.mean(perf_test_accuracy[x]),2))\n",
    "#                    else:\n",
    "#                        plt.text(x-0.33,np.minimum(0.95,np.mean(perf_test_accuracy[x])+0.01),\"{:.2f}\".format(np.mean(perf_test_accuracy[x]),2))\n",
    "                    plt.text(x-plot_barlsh,np.mean(perf_test_accuracy[x])+0.01,\"{:.2f}\".format(np.mean(perf_test_accuracy[x]),2))\n",
    "            elif (f == 1):\n",
    "                for x in range(0,max_technique):\n",
    "                    plt.bar(x,np.mean(perf_test_precision[x],axis=0),label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                    plt.text(x-plot_barlsh,np.mean(perf_test_precision[x])+0.01,\"{:.2f}\".format(np.mean(perf_test_precision[x]),2))\n",
    "            elif (f == 2):\n",
    "                for x in range(0,max_technique):\n",
    "                    plt.bar(x,np.mean(perf_test_recall[x],axis=0),label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                    plt.text(x-plot_barlsh,np.mean(perf_test_recall[x])+0.01,\"{:.2f}\".format(np.mean(perf_test_recall[x]),2))\n",
    "            elif (f == 3):\n",
    "                for x in range(0,max_technique):\n",
    "                    plt.bar(x,np.mean(perf_test_f1[x],axis=0),label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                    plt.text(x-plot_barlsh,np.mean(perf_test_f1[x])+0.01,\"{:.2f}\".format(np.mean(perf_test_f1[x]),2))\n",
    "            elif (f == 4):\n",
    "                for x in range(0,max_technique):\n",
    "                    plt.bar(x,np.mean(perf_test_aucovr[x],axis=0),label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                    plt.text(x-plot_barlsh,np.mean(perf_test_aucovr[x])+0.01,\"{:.2f}\".format(np.mean(perf_test_aucovr[x]),2))\n",
    "            elif (f == 5):\n",
    "                for x in range(0,max_technique):\n",
    "                    plt.bar(x,np.mean(perf_test_aucovo[x],axis=0),label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                    plt.text(x-plot_barlsh,np.mean(perf_test_aucovo[x])+0.01,\"{:.2f}\".format(np.mean(perf_test_aucovo[x]),2))\n",
    "            elif (f == 6):\n",
    "                    plt.bar(x,1-reduction[x]/reduction[0],label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                    plt.text(x-plot_barlsh,1-reduction[x]/reduction[0]+0.01,\"{:.2f}\".format(1-reduction[x]/reduction[0],2))\n",
    "            elif (f == 7):\n",
    "                for x in range(0,max_technique):\n",
    "                    plt.bar(x,1-reduction_class[x]/reduction_class_org,label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "                    plt.text(x-plot_barlsh,1-reduction_class[x]/reduction_class_org+0.01,\"{:.2f}\".format(1-reduction_class[x]/reduction_class_org,2))\n",
    "\n",
    "            plt.savefig(\"performance-\"+str(dataset+1).zfill(2)+\"-\"+str(f+1).zfill(2)+\".pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.02, metadata=None)\n",
    "            plt.close()\n",
    "                     \n",
    "        print(\"Evaluation: Dataset\",dataset,\"is done!\")\n",
    "    print(\"------------------------------------------------------------------------------\\n\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mreduction\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reduction' is not defined"
     ]
    }
   ],
   "source": [
    "reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_class[traintype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2.5))\n",
    "plt.title(str(t),fontsize=14,fontweight='bold')\n",
    "plt.ylabel('Performance (Larger is better)')\n",
    "plt.xticks(range(0,reduction_class.shape[1]))#,label_traintype)\n",
    "plt.xlabel('Class')\n",
    "#plt.ylim([0,1.09])\n",
    "#plt.xlim([0,max_technique])\n",
    "# https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "# https://matplotlib.org/stable/gallery/color/colormap_reference.html\n",
    "cm = plt.cm.get_cmap('tab20')\n",
    "plt.grid(color='grey', linewidth=1, axis='both', alpha=0.2)\n",
    "for c in range(0,reduction_class.shape[1]):\n",
    "    for x in range(0,max_technique): # 1 accuracy, 2 precision, 3 recall, 4 f1-score, 5 aucovr, 6 aucovo, 7 reduction\n",
    "    #    for c in range(len(reduction_class[x])):\n",
    "    #    for c in range(0,reduction_class.shape[1]): # 1 accuracy, 2 precision, 3 recall, 4 f1-score, 5 aucovr, 6 aucovo, 7 reduction\n",
    "        plt.bar(c+x/(max_technique+1),(reduction_class[x]/reduction_class_org)[c],width=1/(max_technique+1),label=label_traintype[x],linewidth=plot_linewidth,alpha=plot_alpha,color=cm.colors[x])\n",
    "        plt.text(c+x/(max_technique+1)-(1/(max_technique*5)),0.05,label_traintype[x],rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xready, tready = mymode_ros.fit_resample(xready, tready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://pymoo.org/algorithms/moo/nsga3.html\n",
    "# pip install -U pymoo\n",
    "\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.factory import get_problem, get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "# create the reference directions to be used for the optimization\n",
    "ref_dirs = get_reference_directions(\"das-dennis\", 3, n_partitions=12)\n",
    "\n",
    "# create the algorithm object\n",
    "algorithm = NSGA3(pop_size=92,\n",
    "                  ref_dirs=ref_dirs)\n",
    "\n",
    "# execute the optimization\n",
    "res = minimize(get_problem(\"dtlz1\"),\n",
    "               algorithm,\n",
    "               seed=1,\n",
    "               termination=('n_gen', 600))\n",
    "\n",
    "Scatter().add(res.F).show()\n",
    "\n",
    "# Reduction\n",
    "\n",
    "res = minimize(get_problem(\"dtlz1^-1\"),\n",
    "               algorithm,\n",
    "               seed=1,\n",
    "               termination=('n_gen', 600))\n",
    "\n",
    "Scatter().add(res.F).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            for i in unique_tready:\n",
    "                reduction_class[traintype,i] = counts_train[i]\n",
    "            reduction_class[traintype-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data set performance comparison\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = [];\n",
    "files_header = [];\n",
    "files_separator = [];\n",
    "#files.append(\"cross_train_accuracy.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "#files.append(\"cross_train_precision.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "#files.append(\"cross_train_recall.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "#files.append(\"cross_train_f1.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "#files.append(\"cross_train_aucovr.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "#files.append(\"cross_train_aucovo.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "files.append(\"cross_test_accuracy.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "files.append(\"cross_test_precision.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "files.append(\"cross_test_recall.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "files.append(\"cross_test_f1.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "files.append(\"cross_test_aucovr.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "files.append(\"cross_test_aucovo.txt\"); files_header.append(None); files_separator.append(\"\\t\"); # 21A4C\n",
    "\n",
    "max_k = 10;\n",
    "max_level = 3;\n",
    "max_set = 7;\n",
    "k_array = []\n",
    "for k in range(0,max_k): k_array.append((2*k)+1); \n",
    "s_array = []\n",
    "for s in range(0,max_set): s_array.append(s+1); \n",
    "\n",
    "perf_title = ('(a) Best Accuracy','(b) Best Precision','(c) Best Recall','(d) Best F1-Score','(e) Best Area Under the Curve (One-vs-Rest)','(f) Best Area Under the Curve (One-vs-One)');\n",
    "label_traintype = ('Original','L1','L1+L2','L1+L2+L3');\n",
    "plot_row = len(files)//2;\n",
    "plot_col = 2;\n",
    "plot_alpha = 0.7;\n",
    "plot_linewidth = 1;\n",
    "\n",
    "raw_max = np.zeros((max_set,max_level+1),dtype = np.float64);\n",
    "figure, axis = plt.subplots(plot_row, plot_col, figsize=(plot_col*10, plot_row*6))\n",
    "for measure in range(0,len(files)):\n",
    "    inputfile = files[measure];\n",
    "    print(\"Measure:\",measure);\n",
    "    print(\"Data Source:\",inputfile);\n",
    "    df = pd.read_csv(inputfile, header = files_header[measure], sep = files_separator[measure]);\n",
    "    raw = df.to_numpy();\n",
    "    #print(raw)\n",
    "    for s in range(0,max_set):\n",
    "        for l in range(0,max_level+1):\n",
    "            raw_max[s][l] = max(raw[s*(max_level+1)+l]);\n",
    "#            print(raw[s*(max_level+1)+l])\n",
    "\n",
    "    for l in range(0,max_level+1):\n",
    "        axis[measure//2,measure%2].plot(s_array,raw_max.T[l],marker='o',label=label_traintype[l],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "    #    print(measure//2,measure%2)\n",
    "\n",
    "#    for d in range(0,max_set): d_array[d] = d+1; \n",
    "#        max_test_accuracy[s][l]=max(raw[][l])\n",
    "\n",
    "#    for l in range(0,max_level+1):\n",
    "#        axis[measure//2,measure%2].plot(k_array,raw[l],marker='o',label=label_traintype[l],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "    for x in range(0,plot_row):\n",
    "        for y in range(0,plot_col):\n",
    "            axis[x,y].set_title(perf_title[x*2+y],fontsize=16)\n",
    "            axis[x,y].set_xlabel('Data Set',fontsize=13)\n",
    "            axis[x,y].set_ylabel('Performance (Larger is better)',fontsize=13)\n",
    "            axis[x,y].set_ylim([0,1])\n",
    "            axis[x,y].legend(loc='lower right')\n",
    "figure.savefig(\"performance-best.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None);\n",
    "\n",
    "print(\"Task completed.\");   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data set performance comparison\n",
    "\n",
    "label_traintype = ('Original','L1','L1+L2','L1+L2+L3');\n",
    "perf_title = ('(a) Best Accuracy','(b) Best Precision','(c) Best Recall','(d) Best F1-Score','(e) Best Area Under the Curve (One-vs-Rest)','(f) Best Area Under the Curve (One-vs-One)','X','X','X');\n",
    "plot_row = 3;\n",
    "plot_col = 2;\n",
    "bar_width = 0.1;\n",
    "\n",
    "d_array = np.zeros((max_set),dtype = np.intc);\n",
    "for d in range(0,max_set): d_array[d] = d+1; \n",
    "for s in range(0,max_set):\n",
    "    for l in range(0,max_level+1):\n",
    "        max_test_accuracy[s][l]=max(global_test_accuracy[s][l])\n",
    "        max_test_precision[s][l]=max(global_test_precision[s][l])\n",
    "        max_test_recall[s][l]=max(global_test_recall[s][l])\n",
    "        max_test_f1[s][l]=max(global_test_f1[s][l])\n",
    "        max_test_auc[s][l]=max(global_test_auc[s][l])\n",
    "        max_test_auc2[s][l]=max(global_test_auc2[s][l])\n",
    "\n",
    "figure, axis = plt.subplots(plot_row, plot_col, figsize=(plot_col*10, plot_row*6))\n",
    "for l in range(0,max_level+1):\n",
    "#    axis[0].plot(d_array,max_test_accuracy.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[1].plot(d_array,max_test_precision.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[2].plot(d_array,max_test_recall.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[3].plot(d_array,max_test_f1.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[4].plot(d_array,max_test_auc.T[l],marker='o',label=label_traintype[l])\n",
    "    axis[0,0].plot(d_array,max_test_accuracy.T[l],marker='o',label=label_traintype[l],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "    axis[0,1].plot(d_array,max_test_precision.T[l],marker='o',label=label_traintype[l],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "    axis[1,0].plot(d_array,max_test_recall.T[l],marker='o',label=label_traintype[l],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "    axis[1,1].plot(d_array,max_test_f1.T[l],marker='o',label=label_traintype[l],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "    axis[2,0].plot(d_array,max_test_auc.T[l],marker='o',label=label_traintype[l],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "    axis[2,1].plot(d_array,max_test_auc2.T[l],marker='o',label=label_traintype[l],linewidth=plot_linewidth,alpha=plot_alpha)\n",
    "#    axis[0,0].scatter(d_array,max_test_accuracy.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[0,1].scatter(d_array,max_test_precision.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[1,0].scatter(d_array,max_test_recall.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[1,1].scatter(d_array,max_test_f1.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[2,0].scatter(d_array,max_test_auc.T[l],marker='o',label=label_traintype[l])\n",
    "#    axis[0,0].bar(d_array*l/5,max_test_accuracy.T[l],width=bar_width,label=label_traintype[l])\n",
    "#    axis[0,1].bar(d_array*l/5,max_test_precision.T[l],width=bar_width,label=label_traintype[l])\n",
    "#    axis[1,0].bar(d_array*l/5,max_test_recall.T[l],width=bar_width,label=label_traintype[l])\n",
    "#    axis[1,1].bar(d_array*l/5,max_test_f1.T[l],width=bar_width,label=label_traintype[l])\n",
    "#    axis[2,0].bar(d_array*l/5,max_test_auc.T[l],width=bar_width,label=label_traintype[l])   \n",
    "    for x in range(0,plot_row):\n",
    "        for y in range(0,plot_col):\n",
    "            axis[x,y].set_title(perf_title[x*2+y],fontsize=16)\n",
    "            axis[x,y].set_xlabel('Data Set',fontsize=13)\n",
    "            axis[x,y].set_ylabel('Performance (Larger is better)',fontsize=13)\n",
    "            axis[x,y].set_ylim([0,1])\n",
    "            axis[x,y].legend(loc='lower right')\n",
    "figure.savefig(\"performance-best.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None);\n",
    "\n",
    "print(\"Task completed.\");\n",
    "\n",
    "# Plot data reduction comparison\n",
    "\n",
    "l_array = np.zeros((max_level),dtype = np.intc);\n",
    "label_traintype = ('L1','L1+L2','L1+L2+L3');\n",
    "reduct_title = ('Data Reduction');\n",
    "\n",
    "scatter_x = traindata[:,0];\n",
    "scatter_y = traindata[:,1];\n",
    "scatter_x_min = min(scatter_x);\n",
    "scatter_x_max = max(scatter_x);\n",
    "scatter_y_min = min(scatter_y);\n",
    "scatter_y_max = max(scatter_y);\n",
    "group = trainlabel;\n",
    "\n",
    "plt.plot();\n",
    "plt.plot(l_array,global_reduction[0:3]);\n",
    "plt.legend(loc='best');\n",
    "plt.ylim([0,1]);\n",
    "#plt.savefig(os.path.basename(inputfile)+\"-org.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None);\n",
    "plt.show();\n",
    "plt.savefig(\"reduction-best.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None);\n",
    "\n",
    "print(\"Task completed.\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_array = np.zeros((max_level),dtype = np.intc);\n",
    "for l in range(0,max_level): l_array[l] = l+1; \n",
    "label_traintype = ('L1','L1+L2','L1+L2+L3');\n",
    "reduct_title = ('Data Reduction');\n",
    "\n",
    "\n",
    "#plt.plot();\n",
    "plt.plot(l_array,global_reduction.T[0:3],marker='o',label=d_array);\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset\n",
    "#    [dataset,traintype,k] = perf_train_aucovr[traintype,k] = statistics.mean(scores[\"train_aucovr\"]);\n",
    "#            global_train_aucovo[dataset,traintype,k] = perf_train_aucovo[traintype,k] = statistics.mean(scores[\"train_aucovo\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Store global\n",
    "    if (dataset == 0):\n",
    "        global_fit_time[0] = perf_fit_time;\n",
    "        global_score_time = perf_score_time;\n",
    "        global_train_accuracy = perf_train_accuracy;\n",
    "        global_train_precision = perf_train_precision;\n",
    "        global_train_recall = perf_train_recall;\n",
    "        global_train_f1 = perf_train_f1;\n",
    "        global_train_auc = perf_train_auc;\n",
    "        global_test_accuracy = perf_test_accuracy;\n",
    "        global_test_precision = perf_test_precision;\n",
    "        global_test_recall = perf_test_recall;\n",
    "        global_test_f1 = perf_test_f1;\n",
    "        global_test_auc = perf_test_auc;\n",
    "    else:\n",
    "        global_fit_time = np.concatenate((global_fit_time,perf_fit_time),axis=0);\n",
    "        global_score_time = np.concatenate((global_score_time,perf_score_time),axis=0);\n",
    "        global_train_accuracy = np.concatenate((global_train_accuracy,perf_train_accuracy),axis=0);\n",
    "        global_train_precision = np.concatenate((global_train_precision,perf_train_precision),axis=0);\n",
    "        global_train_recall = np.concatenate((global_train_recall,perf_train_recall),axis=0);\n",
    "        global_train_f1 = np.concatenate((global_train_f1,perf_train_f1),axis=0);\n",
    "        global_train_auc = np.concatenate((global_train_auc,perf_train_auc),axis=0);\n",
    "        global_test_accuracy = np.concatenate((global_test_accuracy,perf_test_accuracy),axis=0);\n",
    "        global_test_precision = np.concatenate((global_test_precision,perf_test_precision),axis=0);\n",
    "        global_test_recall = np.concatenate((global_test_recall,perf_test_recall),axis=0);\n",
    "        global_test_f1 = np.concatenate((global_test_f1,perf_test_f1),axis=0);\n",
    "        global_test_auc = np.concatenate((global_test_auc,perf_test_auc),axis=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_array,global_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    figure, axis = plt.subplots(4, 2, figsize=(10, 20))\n",
    "#    figure.set_size_inches(10, 10)\n",
    "#    axis.subplots_adjust(bottom=0.3, top=0.7, hspace=0)\n",
    "    for row in range(0,dataset//2):\n",
    "        for col in range(0,2):\n",
    "            axis[row,col].plot(k_array,perf_test_accuracy[0],marker='o',label='Original')\n",
    "            axis[row,col].plot(k_array,perf_test_accuracy[1],marker='o',label='L1')\n",
    "            axis[row,col].plot(k_array,perf_test_accuracy[2],marker='o',label='L1+L2')\n",
    "            axis[row,col].plot(k_array,perf_test_accuracy[3],marker='o',label='L1+L2+L3')\n",
    "            axis[row,col].set_title(str(row*dataset//2+col+1))\n",
    "        #    axis[dataset,0].xlabel('k')\n",
    "        #    axis[dataset,0].ylabel('AUC')\n",
    "            #plt.xlim(xmin = 0, xmax = 10)\n",
    "        #    axis[dataset,0].ylim(ymin = 0, ymax = 1)\n",
    "        #    axis[dataset,0].xticks(k_array,k_array)\n",
    "            axis[row,col].legend(loc='best')\n",
    "        #    plt.savefig(os.path.basename(inputfile)+\"-auc.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None);\n",
    "            figure.savefig(str(dataset+1).zfill(2)+\"-auc.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None);\n",
    "        #    figure.show()                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del global_fit_time\\\n",
    "global_fit_time = [] * 10\n",
    "#global_fit_time = np.concatenate((global_fit_time,perf_fit_time),axis=0);\n",
    "global_fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.SCORERS.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del best_fit_time\n",
    "best_fit_time = np.zeros((0,max_measure),dtype = np.float64);\n",
    "print(perf_fit_time[traintype]);\n",
    "best_fit_time = perf_fit_time[traintype];\n",
    "np.concatenate((best_fit_time,perf_fit_time[traintype]),axis=0);\n",
    "print(best_fit_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "plt.scatter([0] * max_measure,perf_test_accuracy[0],marker='.',s=5,label='Original')\n",
    "plt.scatter([reduction[0]/reduction[0]] * max_measure,perf_test_accuracy[1],marker='.',s=5,label='L1')\n",
    "plt.scatter([reduction[1]/reduction[0]] * max_measure,perf_test_accuracy[2],marker='.',s=5,label='L1+L2')\n",
    "plt.scatter([reduction[2]/reduction[0]] * max_measure,perf_test_accuracy[3],marker='.',s=5,label='L1+L2+L3')\n",
    "plt.title('AUC Comparison')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('AUC')\n",
    "#plt.xlim(xmin = 0, xmax = 10)\n",
    "plt.ylim(ymin = 0, ymax = 1)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.basename(inputfile)+\"-auc.pdf\", format=\"pdf\", dpi=None, facecolor=\"w\", edgecolor=\"w\", orientation=\"portrait\", transparent=True, bbox_inches=\"tight\", pad_inches=0.1, metadata=None);\n",
    "plt.show()                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KD-Tree Generating L1, L2, L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/neighbors.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html\n",
    "#from sklearn.neighbors import KDTree\n",
    "# print(sorted(KDTree.valid_metrics))\n",
    "#tree = KDTree(traindata, leaf_size=2)\n",
    "\n",
    "# Split dataset into subsets based on class value\n",
    "datasets = {}\n",
    "if (files_label == [-1]):\n",
    "    by_class = df.groupby(df.shape[1]-1)\n",
    "else:\n",
    "    by_class = df.groupby(files_label)\n",
    "    \n",
    "for groups, data in by_class:\n",
    "    datasets[groups] = data\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=2, radius=0.4)\n",
    "for x in range(0,groups):\n",
    "    neigh.fit(datasets[x])\n",
    "    for y in range(0,groups):\n",
    "        print(neigh.kneighbors(datasets[y].values[0].reshape(1,-1), 2, return_distance=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reduction_class_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[\"train_aucovo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data set #1\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max = 300;\n",
    "y1 = np.zeros((max),np.float64)\n",
    "y2 = np.zeros((max),np.float64)\n",
    "y3 = np.zeros((max),np.float64)\n",
    "# y4 = np.zeros((max),np.float64)\n",
    "# y5 = np.zeros((max),np.float64)\n",
    "for x in range(0,max):\n",
    "    y1[x] = math.sin(x/10)+np.random.random_sample()*3\n",
    "    y2[x] = math.sin(x/10)+3+np.random.random_sample()*3\n",
    "    y3[x] = math.sin(x/10)+6+np.random.random_sample()*3\n",
    "#     y4[x] = math.sin(x/10)+6+np.random.random_sample()+np.random.random_sample()\n",
    "#     y5[x] = math.sin(x/10)+8+np.random.random_sample()+np.random.random_sample()\n",
    "fig = plt.figure(figsize=(20,10));\n",
    "xx = np.array(range(0,max));\n",
    "plt.plot(xx,y1,'.',markersize=1);\n",
    "plt.plot(xx,y2,'.',markersize=1);\n",
    "plt.plot(xx,y3,'.',markersize=1);\n",
    "\n",
    "# plt.plot(range(0,max),y4,'.',markersize=3)\n",
    "# plt.plot(range(0,max),y5,'.',markersize=3)\n",
    "#z = np.vstack((x,y))\n",
    "# with open(\"sine.txt\", \"ab\") as file:\n",
    "#     np.savetxt(file, x.reshape(1,max_level), delimiter='\\t', fmt='%1.4f')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = raw[:,21]\n",
    "enc = OneHotEncoder();\n",
    "OneHotEncoder(categories='auto', drop=None, sparse=True, handle_unknown='error')\n",
    "enc.fit(raw[:,21].reshape(-1, 1))\n",
    "#print(enc.categories_)\n",
    "enc.fit_transform(raw[:,21].reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_train_aucovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_array,max(global_test_accuracy[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        dflist = df.dtypes.tolist()\n",
    "        for i in range(0,len(dflist)):\n",
    "            if(dflist[i]==\"object\"):\n",
    "                print(i,\"E \",end=\"\",sep=\"\");\n",
    "                # creating instance of one-hot-encoder\n",
    "                enc = OneHotEncoder(handle_unknown='ignore')\n",
    "                # passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "                OneHotEncoder(categories='auto', drop=True, sparse=True, handle_unknown='error')\n",
    "                #print(enc.categories_)\n",
    "                encode_temp = enc.fit_transform(raw[:,i].reshape(-1,1)).toarray()\n",
    "                print(encode_temp)\n",
    "            else:\n",
    "                print(i,\" \",end=\"\",sep=\"\");\n",
    "        print(\") (OneHotEncoding)\");\n",
    "print(encode_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    inputfile = files[dataset];\n",
    "    print(\"Dataset:\",dataset);\n",
    "    print(\"Data Source:\",inputfile);\n",
    "    if (inputfile[-2:] == \"gz\"):\n",
    "        df = pd.read_csv(inputfile, header = files_header[dataset], sep = files_separator[dataset], compression=\"gzip\");\n",
    "    elif (inputfile[-3:] == \".zip\"):\n",
    "        df = pd.read_csv(inputfile, header = files_header[dataset], sep = files_separator[dataset], compression=\"zip\");\n",
    "    elif (inputfile[-4:] == \".xls\") or (inputfile[-4:] == \"xlsx\"):\n",
    "        df = pd.read_excel(inputfile, header = files_header[dataset]);      \n",
    "    else:\n",
    "        df = pd.read_csv(inputfile, header = files_header[dataset], sep = files_separator[dataset]);\n",
    "    raw = df.to_numpy();\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(inputfile, header = 0, sep = files_separator[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure.ylim(ymin = 0, ymax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d = np.zeros((10),dtype = np.intc);\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_fit_time[dataset,traintype,k] = perf_fit_time[traintype,k] = statistics.mean(scores[\"fit_time\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(np.unique(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
